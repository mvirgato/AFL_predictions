{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AFL Match Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import json\n",
    "plt.style.use(['mvstyle', 'one_piece'])\n",
    "\n",
    "import numpy as np\n",
    "import requests\n",
    "import pandas as pd\n",
    "from os.path import isfile\n",
    "from glob import glob\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = np.arange(1970, 2025)\n",
    "headers = {'User-Agent':'MV_tipping_predictions'}\n",
    "\n",
    "for year in years:\n",
    "\n",
    "    if isfile(f'Seasonal_Data/data_{year:d}.csv'):\n",
    "\n",
    "        # print('Data already downloaded.')\n",
    "        \n",
    "        continue\n",
    "\n",
    "    response = requests.get(f'https://api.squiggle.com.au/?q=games;year={year:d};format=csv', headers=headers)\n",
    "\n",
    "    with open(f'Seasonal_Data/data_{year:d}.csv', 'w') as f:\n",
    "        f.write(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the standings for each round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounds = np.arange(1, 29)\n",
    "\n",
    "for year in years:\n",
    "    try:\n",
    "        os.mkdir(f'Standings/{year:d}/')\n",
    "    except:\n",
    "        pass\n",
    "    for round_ in rounds:\n",
    "\n",
    "        if isfile(f'Standings/{year:d}/round_{round_:d}.csv'):\n",
    "\n",
    "            # print('Data already downloaded.')\n",
    "            \n",
    "            continue\n",
    "        \n",
    "        response = requests.get(f'https://api.squiggle.com.au/?q=standings;year={year:d};round={round_};format=csv', headers=headers)\n",
    "\n",
    "        with open(f'Standings/{year:d}/round_{round_:d}.csv', 'w') as f:\n",
    "            f.write(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some helper functions for use later\n",
    "\n",
    "def get_year(file):\n",
    "    \n",
    "    file = re.sub('^Seasonal_Data/data_', '', file)    \n",
    "    file = file.rstrip('.csv')\n",
    "\n",
    "    return int(file)\n",
    "\n",
    "def get_round(file):\n",
    "    \n",
    "    file = re.sub('^Standings/\\w+/round_', '', file)    \n",
    "    file = file.rstrip('.csv')\n",
    "\n",
    "    return int(file)\n",
    "\n",
    "def read_ranking(file):\n",
    "\n",
    "    _round = get_round(file)\n",
    "\n",
    "    _df  = pd.read_csv(file)\n",
    "\n",
    "    _df.insert(loc=0, column='round', value=_round * np.ones(len(_df), dtype= int))\n",
    "\n",
    "    return _df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read in ranking, number of wins and number of losses\n",
    "# for each team for each round\n",
    "\n",
    "def standings_data(year):\n",
    "    rank_files = glob(f'Standings/{year:d}/*')\n",
    "\n",
    "    standings_frame = pd.concat(read_ranking(file) for file in rank_files)\n",
    "\n",
    "    # Fill NaN values for rank in finals rounds with the mean of the \n",
    "    # team's rank # throughout the season\n",
    "    standings_frame['rank'] = standings_frame['rank'].fillna(\n",
    "        standings_frame.groupby('id')['rank'].transform('mean')\n",
    "        )\n",
    "\n",
    "    standings_frame = standings_frame[['round', 'id', 'rank', 'wins','losses']]\n",
    "    standings_frame = standings_frame.sort_values('round')\n",
    "    standings_frame = standings_frame.reset_index(drop=True)\n",
    "\n",
    "    return standings_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_standings(main_data, standings_data):\n",
    "\n",
    "    lookup = standings_data[['round', 'id', 'rank', 'wins', 'losses']]\n",
    "\n",
    "    # Merge with standings_data to filter matching rows\n",
    "    for prefix in ['h', 'a']:\n",
    "\n",
    "        filtered_main_data = main_data.merge(lookup, left_on=['round', f'{prefix}teamid'], right_on=['round', 'id'], how='inner')\n",
    "        filtered_main_data = filtered_main_data.rename(columns= {'rank':f'{prefix}rank', 'wins': f'{prefix}wins', 'losses': f'{prefix}losses'})\n",
    "        main_data = filtered_main_data.drop('id', axis=1)\n",
    "\n",
    "    return main_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Team info to tranlate ID and team name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_data = requests.get('https://api.squiggle.com.au/?q=teams;format=csv', headers=headers)\n",
    "\n",
    "with open('team_data.csv', 'w') as f:\n",
    "    f.write(team_data.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_data = pd.read_csv('team_data.csv', index_col=None)\n",
    "# team_dict = team_data[['name', 'id']].to_dict('index')\n",
    "names = team_data['name'].to_numpy()\n",
    "ids = team_data['id'].to_numpy()\n",
    "\n",
    "team_dict = {id_ : name for id_, name in zip(ids, names)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function to process the raw data into the statistics we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_season_data(datafile):\n",
    "\n",
    "    # Select relevant columns\n",
    "\n",
    "    dataframe = pd.read_csv(datafile)\n",
    "\n",
    "    dataframe = dataframe[['round', 'hteamid', 'ateamid', 'hscore', \n",
    "                           'ascore', 'hgoals', 'agoals', 'hbehinds', \n",
    "                           'abehinds', 'is_final', 'winnerteamid']].copy()\n",
    "\n",
    "    # Fill NaN values in winnerteamid\n",
    "    dataframe['winnerteamid'] = dataframe['winnerteamid'].fillna(0)\n",
    "\n",
    "    # Compute hteamwin using np.where()\n",
    "    dataframe['hteamwin'] = np.where(\n",
    "        dataframe['winnerteamid'] == 0, 2, \n",
    "        np.where(dataframe['winnerteamid'] == dataframe['hteamid'], 1, 0)\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    # Compute expanding mean for each team using groupby()\n",
    "    column_team_mapping = { \n",
    "        'hscore': 'hteamid', 'hgoals': 'hteamid', 'hbehinds': 'hteamid', \n",
    "        'ascore': 'ateamid', 'agoals': 'ateamid', 'abehinds': 'ateamid' \n",
    "        }\n",
    "\n",
    "    # Compute expanding means efficiently in a single loop\n",
    "    for col, team_col in column_team_mapping.items():\n",
    "        dataframe[f'{col}_ppg'] = (\n",
    "            dataframe.groupby(team_col)[col]\n",
    "            .expanding().mean()\n",
    "            .reset_index(level=0, drop=True)\n",
    "        )\n",
    "    \n",
    "    year = get_year(datafile)\n",
    "    dataframe = merge_standings(dataframe, standings_data(year))\n",
    "\n",
    "    # Select final columns\n",
    "    final_data = dataframe[['round', \n",
    "                            'hteamid', 'ateamid',\n",
    "                            'hrank', 'arank', \n",
    "                            'hscore_ppg', 'ascore_ppg', \n",
    "                            'hgoals_ppg', 'agoals_ppg', \n",
    "                            'hbehinds_ppg', 'abehinds_ppg', \n",
    "                            'hwins', 'awins', \n",
    "                            'hlosses', 'alosses',  \n",
    "                            'is_final', 'hteamwin']].copy()\n",
    "    \n",
    "    \n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine all seasonal data into one DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9476"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_files = glob('Seasonal_Data/data_*.csv')\n",
    "full_data = pd.concat(process_season_data(file) for file in data_files)\n",
    "full_data.__len__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Nets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process data for use in neural nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import functional\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PandasDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataframe):\n",
    "        self.data = dataframe.drop(columns=['hteamwin']).values  # Features\n",
    "        self.labels = dataframe['hteamwin'].values.astype(np.int16)  # Targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.tensor(self.data[idx], dtype=torch.float32)\n",
    "        y = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_data = PandasDataset(full_data)\n",
    "\n",
    "\n",
    "train_proportion = 0.7\n",
    "val_proportion = 1.0 - train_proportion\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "train_data, val_data = train_test_split(main_data, train_size=train_proportion, shuffle=True, random_state=42)\n",
    "\n",
    "train_loader = DataLoader(train_data, \n",
    "                          shuffle=True, \n",
    "                          num_workers=2, \n",
    "                          batch_size=batch_size\n",
    "                          )\n",
    "\n",
    "val_loader = DataLoader(val_data, \n",
    "                        shuffle=True, \n",
    "                        num_workers=2, \n",
    "                        batch_size=batch_size\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test speed of data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0007592058181762696 [s/iteration]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "tstart=time.time()\n",
    "num_iter=100\n",
    "ctr=num_iter\n",
    "for batch in train_loader:\n",
    "    ctr -=100\n",
    "    if ctr <= 0: break\n",
    "print((time.time()-tstart)/num_iter,'[s/iteration]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense Neural Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the neural network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_nodes = 24\n",
    "output_nodes = 3\n",
    "\n",
    "class DenseNN(nn.Module):\n",
    "    def __init__(self,inputNum):\n",
    "\n",
    "        super(DenseNN, self).__init__()\n",
    "        \n",
    "        self.inputNum=inputNum\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=inputNum, out_features=hidden_nodes)  # Input layer\n",
    "        self.fc2 = nn.Linear(in_features=hidden_nodes, out_features=hidden_nodes)     # Hidden layer\n",
    "        self.fc3 = nn.Linear(in_features=hidden_nodes, out_features=hidden_nodes)     # Hidden layer\n",
    "        self.fc4 = nn.Linear(in_features=hidden_nodes, out_features=hidden_nodes)     # Hidden layer\n",
    "        # self.fc5 = nn.Linear(in_features=hidden_nodes, out_features=hidden_nodes)     # Hidden layer\n",
    "        self.fc5 = nn.Linear(in_features=hidden_nodes, out_features=output_nodes)     # Output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = x.view(-1, self.inputNum)   # Flatten the input\n",
    "        \n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = torch.relu(self.fc4(x))\n",
    "        # x = torch.relu(self.fc5(x))\n",
    "        x = self.fc5(x)\n",
    "\n",
    "        return functional.softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch:  0\n",
      "batch:  9  loss =  1.0446126129892137\n",
      "batch:  19  loss =  0.9953928213370474\n",
      "batch:  29  loss =  0.966625505480273\n",
      "batch:  39  loss =  0.9461510532941574\n",
      "batch:  49  loss =  0.9269329297299288\n",
      "batch:  59  loss =  0.908940128350662\n",
      "End train epoch, mean loss:  0.8958645240584416\n",
      "batch:  9  loss =  0.79226463370853\n",
      "batch:  19  loss =  0.7887115102065237\n",
      "batch:  29  loss =  0.7892618035448009\n",
      "End val epoch, mean loss:  0.7892618035448009\n",
      "In epoch:  1\n",
      "batch:  9  loss =  0.792822003364563\n",
      "batch:  19  loss =  0.7983236657945734\n",
      "batch:  29  loss =  0.7921648950412356\n",
      "batch:  39  loss =  0.7898661769353427\n",
      "batch:  49  loss =  0.7889240104324964\n",
      "batch:  59  loss =  0.7861069481251604\n",
      "End train epoch, mean loss:  0.7817924734371812\n",
      "batch:  9  loss =  0.7917690144644843\n",
      "batch:  19  loss =  0.774197939195131\n",
      "batch:  29  loss =  0.7731948947084362\n",
      "End val epoch, mean loss:  0.7731948947084362\n",
      "In epoch:  2\n",
      "batch:  9  loss =  0.7791112330224779\n",
      "batch:  19  loss =  0.7725295079381842\n",
      "batch:  29  loss =  0.7655228211961943\n",
      "batch:  39  loss =  0.7633288044195908\n",
      "batch:  49  loss =  0.7630557527347487\n",
      "batch:  59  loss =  0.7636185540991315\n",
      "End train epoch, mean loss:  0.763425539678602\n",
      "batch:  9  loss =  0.759656912750668\n",
      "batch:  19  loss =  0.7586221287125036\n",
      "batch:  29  loss =  0.7641116257371574\n",
      "End val epoch, mean loss:  0.7641116257371574\n",
      "In epoch:  3\n",
      "batch:  9  loss =  0.7613845268885294\n",
      "batch:  19  loss =  0.7656911329219216\n",
      "batch:  29  loss =  0.7654039037638697\n",
      "batch:  39  loss =  0.7664197698617593\n",
      "batch:  49  loss =  0.7659613903687925\n",
      "batch:  59  loss =  0.7640797657481695\n",
      "End train epoch, mean loss:  0.7629151148582572\n",
      "batch:  9  loss =  0.7474188605944315\n",
      "batch:  19  loss =  0.758560017535561\n",
      "batch:  29  loss =  0.761278602583655\n",
      "End val epoch, mean loss:  0.761278602583655\n",
      "In epoch:  4\n",
      "batch:  9  loss =  0.7465498778555129\n",
      "batch:  19  loss =  0.7483896111187182\n",
      "batch:  29  loss =  0.7565478107024883\n",
      "batch:  39  loss =  0.7499578717427376\n",
      "batch:  49  loss =  0.7562133012985697\n",
      "batch:  59  loss =  0.7574851341166738\n",
      "End train epoch, mean loss:  0.757064171691439\n",
      "batch:  9  loss =  0.7547797428237067\n",
      "batch:  19  loss =  0.7486353579320406\n",
      "batch:  29  loss =  0.760148915751227\n",
      "End val epoch, mean loss:  0.760148915751227\n",
      "In epoch:  5\n",
      "batch:  9  loss =  0.7543695171674093\n",
      "batch:  19  loss =  0.7681311588538321\n",
      "batch:  29  loss =  0.7662922801642582\n",
      "batch:  39  loss =  0.7674617278270233\n",
      "batch:  49  loss =  0.7648553325205433\n",
      "batch:  59  loss =  0.7634713649749756\n",
      "End train epoch, mean loss:  0.7614065364225587\n",
      "batch:  9  loss =  0.7795899311701456\n",
      "batch:  19  loss =  0.765991703460091\n",
      "batch:  29  loss =  0.7639987879785998\n",
      "End val epoch, mean loss:  0.7639987879785998\n",
      "In epoch:  6\n",
      "batch:  9  loss =  0.7886300484339396\n",
      "batch:  19  loss =  0.7738639429995888\n",
      "batch:  29  loss =  0.7712040194149675\n",
      "batch:  39  loss =  0.7679514564000643\n",
      "batch:  49  loss =  0.7649877886382901\n",
      "batch:  59  loss =  0.7624208906949577\n",
      "End train epoch, mean loss:  0.7670365589768139\n",
      "batch:  9  loss =  0.7590205868085226\n",
      "batch:  19  loss =  0.7726443598144933\n",
      "batch:  29  loss =  0.7707538337543093\n",
      "End val epoch, mean loss:  0.7707538337543093\n",
      "In epoch:  7\n",
      "batch:  9  loss =  0.7643671101993985\n",
      "batch:  19  loss =  0.7627768547911393\n",
      "batch:  29  loss =  0.7585283558944176\n",
      "batch:  39  loss =  0.759106579499367\n",
      "batch:  49  loss =  0.7562266649032126\n",
      "batch:  59  loss =  0.7600683377960981\n",
      "End train epoch, mean loss:  0.7567459807467105\n",
      "batch:  9  loss =  0.7589750289916992\n",
      "batch:  19  loss =  0.7590572865385758\n",
      "batch:  29  loss =  0.7595777676023286\n",
      "End val epoch, mean loss:  0.7595777676023286\n",
      "In epoch:  8\n",
      "batch:  9  loss =  0.752331468794081\n",
      "batch:  19  loss =  0.7576616971116317\n",
      "batch:  29  loss =  0.7612809230541361\n",
      "batch:  39  loss =  0.7592290517611381\n",
      "batch:  49  loss =  0.7561515667000596\n",
      "batch:  59  loss =  0.7569378745757928\n",
      "End train epoch, mean loss:  0.757379412651062\n",
      "batch:  9  loss =  0.7505242625872294\n",
      "batch:  19  loss =  0.7530551960593775\n",
      "batch:  29  loss =  0.7623168230056763\n",
      "End val epoch, mean loss:  0.7623168230056763\n",
      "In epoch:  9\n",
      "batch:  9  loss =  0.7801928917566935\n",
      "batch:  19  loss =  0.761127864059649\n",
      "batch:  29  loss =  0.7631584179812464\n",
      "batch:  39  loss =  0.7655087312062582\n",
      "batch:  49  loss =  0.7617405957105209\n",
      "batch:  59  loss =  0.7616224925396806\n",
      "End train epoch, mean loss:  0.7600302260313461\n",
      "batch:  9  loss =  0.7586514618661668\n",
      "batch:  19  loss =  0.7644300147106773\n",
      "batch:  29  loss =  0.7661168287540304\n",
      "End val epoch, mean loss:  0.7661168287540304\n",
      "In epoch:  10\n",
      "batch:  9  loss =  0.7547387745645311\n",
      "batch:  19  loss =  0.7548274742929559\n",
      "batch:  29  loss =  0.7632917165756226\n",
      "batch:  39  loss =  0.760153516744956\n",
      "batch:  49  loss =  0.7595557193366849\n",
      "batch:  59  loss =  0.7590804726390515\n",
      "End train epoch, mean loss:  0.7577651899252364\n",
      "batch:  9  loss =  0.7676791548728943\n",
      "batch:  19  loss =  0.7654395448534113\n",
      "batch:  29  loss =  0.7583154953759292\n",
      "End val epoch, mean loss:  0.7583154953759292\n",
      "In epoch:  11\n",
      "batch:  9  loss =  0.7581763929790921\n",
      "batch:  19  loss =  0.7723353222796792\n",
      "batch:  29  loss =  0.767814445084539\n",
      "batch:  39  loss =  0.7637083606842237\n",
      "batch:  49  loss =  0.7582102892350178\n",
      "batch:  59  loss =  0.7558269066325689\n",
      "End train epoch, mean loss:  0.7557731929110058\n",
      "batch:  9  loss =  0.760691848066118\n",
      "batch:  19  loss =  0.7617868404639395\n",
      "batch:  29  loss =  0.759013451378921\n",
      "End val epoch, mean loss:  0.759013451378921\n",
      "In epoch:  12\n",
      "batch:  9  loss =  0.7543753054406908\n",
      "batch:  19  loss =  0.7556007065271076\n",
      "batch:  29  loss =  0.7511461500463814\n",
      "batch:  39  loss =  0.7492351012352185\n",
      "batch:  49  loss =  0.7510818316012012\n",
      "batch:  59  loss =  0.7554304084535373\n",
      "End train epoch, mean loss:  0.7567079983540436\n",
      "batch:  9  loss =  0.7742343147595724\n",
      "batch:  19  loss =  0.7687286295388874\n",
      "batch:  29  loss =  0.7618311725813767\n",
      "End val epoch, mean loss:  0.7618311725813767\n",
      "In epoch:  13\n",
      "batch:  9  loss =  0.7643859916263156\n",
      "batch:  19  loss =  0.764847855818899\n",
      "batch:  29  loss =  0.7657451794065279\n",
      "batch:  39  loss =  0.7626077609184461\n",
      "batch:  49  loss =  0.7584485752241952\n",
      "batch:  59  loss =  0.7575575436575938\n",
      "End train epoch, mean loss:  0.7582355132743493\n",
      "batch:  9  loss =  0.761760499742296\n",
      "batch:  19  loss =  0.7611108924213209\n",
      "batch:  29  loss =  0.759841331120195\n",
      "End val epoch, mean loss:  0.759841331120195\n",
      "In epoch:  14\n",
      "batch:  9  loss =  0.7601446310679117\n",
      "batch:  19  loss =  0.7543104416445682\n",
      "batch:  29  loss =  0.7531927824020386\n",
      "batch:  39  loss =  0.7547257313361535\n",
      "batch:  49  loss =  0.757574586235747\n",
      "batch:  59  loss =  0.7573021448264687\n",
      "End train epoch, mean loss:  0.7576864388451647\n",
      "batch:  9  loss =  0.7667724622620476\n",
      "batch:  19  loss =  0.7631374691662035\n",
      "batch:  29  loss =  0.7598618844459797\n",
      "End val epoch, mean loss:  0.7598618844459797\n",
      "In epoch:  15\n",
      "batch:  9  loss =  0.7372513082292345\n",
      "batch:  19  loss =  0.7412438863202145\n",
      "batch:  29  loss =  0.7518301503411655\n",
      "batch:  39  loss =  0.7517445393097706\n",
      "batch:  49  loss =  0.7552506437107008\n",
      "batch:  59  loss =  0.7556603015479395\n",
      "End train epoch, mean loss:  0.7558048216264639\n",
      "batch:  9  loss =  0.7548231879870096\n",
      "batch:  19  loss =  0.7552312549791838\n",
      "batch:  29  loss =  0.7597733201651737\n",
      "End val epoch, mean loss:  0.7597733201651737\n",
      "In epoch:  16\n",
      "batch:  9  loss =  0.7604683968755934\n",
      "batch:  19  loss =  0.7534378202337968\n",
      "batch:  29  loss =  0.7563063605078335\n",
      "batch:  39  loss =  0.7604546760901426\n",
      "batch:  49  loss =  0.7579695497240339\n",
      "batch:  59  loss =  0.7566490052110058\n",
      "End train epoch, mean loss:  0.7555479247178605\n",
      "batch:  9  loss =  0.7452233698632982\n",
      "batch:  19  loss =  0.7605267857250414\n",
      "batch:  29  loss =  0.7567192089968714\n",
      "End val epoch, mean loss:  0.7567192089968714\n",
      "In epoch:  17\n",
      "batch:  9  loss =  0.7467301487922668\n",
      "batch:  19  loss =  0.7415558695793152\n",
      "batch:  29  loss =  0.7464375084844129\n",
      "batch:  39  loss =  0.7524722325496185\n",
      "batch:  49  loss =  0.7498247878892081\n",
      "batch:  59  loss =  0.7526997711698887\n",
      "End train epoch, mean loss:  0.7546816281418303\n",
      "batch:  9  loss =  0.7595140669080946\n",
      "batch:  19  loss =  0.7560964791398299\n",
      "batch:  29  loss =  0.760228459177346\n",
      "End val epoch, mean loss:  0.760228459177346\n",
      "In epoch:  18\n",
      "batch:  9  loss =  0.7439653078715006\n",
      "batch:  19  loss =  0.7547738301126581\n",
      "batch:  29  loss =  0.7588141745534437\n",
      "batch:  39  loss =  0.7569071130874829\n",
      "batch:  49  loss =  0.7557661192757743\n",
      "batch:  59  loss =  0.7558813620421846\n",
      "End train epoch, mean loss:  0.7538124767702017\n",
      "batch:  9  loss =  0.7539467016855875\n",
      "batch:  19  loss =  0.7537874924509149\n",
      "batch:  29  loss =  0.7569360116432453\n",
      "End val epoch, mean loss:  0.7569360116432453\n",
      "In epoch:  19\n",
      "batch:  9  loss =  0.7601587573687235\n",
      "batch:  19  loss =  0.7575687201399552\n",
      "batch:  29  loss =  0.7491033015580013\n",
      "batch:  39  loss =  0.7504334312218887\n",
      "batch:  49  loss =  0.7507566615026824\n",
      "batch:  59  loss =  0.7534758862802537\n",
      "End train epoch, mean loss:  0.7546330886100655\n",
      "batch:  9  loss =  0.7545201645957099\n",
      "batch:  19  loss =  0.759302534555134\n",
      "batch:  29  loss =  0.7574713189026405\n",
      "End val epoch, mean loss:  0.7574713189026405\n",
      "In epoch:  20\n",
      "batch:  9  loss =  0.7522824870215522\n",
      "batch:  19  loss =  0.7445368547188608\n",
      "batch:  29  loss =  0.7554425884937418\n",
      "batch:  39  loss =  0.7528929037925525\n",
      "batch:  49  loss =  0.7544700819618848\n",
      "batch:  59  loss =  0.7563319670951972\n",
      "End train epoch, mean loss:  0.7548706398081424\n",
      "batch:  9  loss =  0.7403141856193542\n",
      "batch:  19  loss =  0.7588637063377782\n",
      "batch:  29  loss =  0.7632313925644447\n",
      "End val epoch, mean loss:  0.7632313925644447\n",
      "In epoch:  21\n",
      "batch:  9  loss =  0.7644803722699484\n",
      "batch:  19  loss =  0.7631536628070631\n",
      "batch:  29  loss =  0.7571657299995422\n",
      "batch:  39  loss =  0.7565020903562888\n",
      "batch:  49  loss =  0.7551592478946764\n",
      "batch:  59  loss =  0.7543644369658777\n",
      "End train epoch, mean loss:  0.7541996071587748\n",
      "batch:  9  loss =  0.7555309997664558\n",
      "batch:  19  loss =  0.7526568990004691\n",
      "batch:  29  loss =  0.7569244647848195\n",
      "End val epoch, mean loss:  0.7569244647848195\n",
      "In epoch:  22\n",
      "batch:  9  loss =  0.7660933203167386\n",
      "batch:  19  loss =  0.7698084523803309\n",
      "batch:  29  loss =  0.7634330350777199\n",
      "batch:  39  loss =  0.7607397467662127\n",
      "batch:  49  loss =  0.7560831186722736\n",
      "batch:  59  loss =  0.7554106722443791\n",
      "End train epoch, mean loss:  0.7535271208677718\n",
      "batch:  9  loss =  0.7626889480484856\n",
      "batch:  19  loss =  0.751673140023884\n",
      "batch:  29  loss =  0.7574186242859939\n",
      "End val epoch, mean loss:  0.7574186242859939\n",
      "In epoch:  23\n",
      "batch:  9  loss =  0.7294235825538635\n",
      "batch:  19  loss =  0.7394957322823373\n",
      "batch:  29  loss =  0.7484239319275166\n",
      "batch:  39  loss =  0.7481669905858163\n",
      "batch:  49  loss =  0.7470543068282458\n",
      "batch:  59  loss =  0.7505826636896296\n",
      "End train epoch, mean loss:  0.7547809054602438\n",
      "batch:  9  loss =  0.7456911206245422\n",
      "batch:  19  loss =  0.7561541011458949\n",
      "batch:  29  loss =  0.7591259253436121\n",
      "End val epoch, mean loss:  0.7591259253436121\n",
      "In epoch:  24\n",
      "batch:  9  loss =  0.7592104805840386\n",
      "batch:  19  loss =  0.7619418094032689\n",
      "batch:  29  loss =  0.7610463315042956\n",
      "batch:  39  loss =  0.7585256955562494\n",
      "batch:  49  loss =  0.7552774183604182\n",
      "batch:  59  loss =  0.7547749381954387\n",
      "End train epoch, mean loss:  0.7549155514631698\n",
      "batch:  9  loss =  0.7611407571368747\n",
      "batch:  19  loss =  0.7493004296955309\n",
      "batch:  29  loss =  0.7597794984949047\n",
      "End val epoch, mean loss:  0.7597794984949047\n",
      "In epoch:  25\n",
      "batch:  9  loss =  0.7354366183280945\n",
      "batch:  19  loss =  0.7392185142165736\n",
      "batch:  29  loss =  0.7494702791345531\n",
      "batch:  39  loss =  0.7517156738501328\n",
      "batch:  49  loss =  0.7544100795473371\n",
      "batch:  59  loss =  0.755077782323805\n",
      "End train epoch, mean loss:  0.7541877920947858\n",
      "batch:  9  loss =  0.7574264605840048\n",
      "batch:  19  loss =  0.758660614490509\n",
      "batch:  29  loss =  0.7604443040387384\n",
      "End val epoch, mean loss:  0.7604443040387384\n",
      "In epoch:  26\n",
      "batch:  9  loss =  0.7615165710449219\n",
      "batch:  19  loss =  0.7670741363575584\n",
      "batch:  29  loss =  0.7646970872221321\n",
      "batch:  39  loss =  0.7600376300322704\n",
      "batch:  49  loss =  0.7589400289010029\n",
      "batch:  59  loss =  0.7551682066109221\n",
      "End train epoch, mean loss:  0.7547062777761203\n",
      "batch:  9  loss =  0.7629053791364034\n",
      "batch:  19  loss =  0.7568526048409311\n",
      "batch:  29  loss =  0.7582221627235413\n",
      "End val epoch, mean loss:  0.7582221627235413\n",
      "In epoch:  27\n",
      "batch:  9  loss =  0.7361526290575663\n",
      "batch:  19  loss =  0.7499405365241202\n",
      "batch:  29  loss =  0.7487189481998312\n",
      "batch:  39  loss =  0.7470857944243994\n",
      "batch:  49  loss =  0.7488735573632377\n",
      "batch:  59  loss =  0.7509196198592751\n",
      "End train epoch, mean loss:  0.7532127552957677\n",
      "batch:  9  loss =  0.7618393037054274\n",
      "batch:  19  loss =  0.7504685740721854\n",
      "batch:  29  loss =  0.7555123732007784\n",
      "End val epoch, mean loss:  0.7555123732007784\n",
      "In epoch:  28\n",
      "batch:  9  loss =  0.7654165559344821\n",
      "batch:  19  loss =  0.7412497181641428\n",
      "batch:  29  loss =  0.7476660115965481\n",
      "batch:  39  loss =  0.7465456097553937\n",
      "batch:  49  loss =  0.7532444365170538\n",
      "batch:  59  loss =  0.7544133026721114\n",
      "End train epoch, mean loss:  0.7543132803333339\n",
      "batch:  9  loss =  0.7398892045021057\n",
      "batch:  19  loss =  0.7578216697040357\n",
      "batch:  29  loss =  0.7559581583943861\n",
      "End val epoch, mean loss:  0.7559581583943861\n",
      "In epoch:  29\n",
      "batch:  9  loss =  0.7741351392534044\n",
      "batch:  19  loss =  0.7685424497253016\n",
      "batch:  29  loss =  0.7612289519145571\n",
      "batch:  39  loss =  0.7577607677533076\n",
      "batch:  49  loss =  0.7561309070003276\n",
      "batch:  59  loss =  0.7546523061849303\n",
      "End train epoch, mean loss:  0.75738355294982\n",
      "batch:  9  loss =  0.7355118857489692\n",
      "batch:  19  loss =  0.7578110443918329\n",
      "batch:  29  loss =  0.7559078417975327\n",
      "End val epoch, mean loss:  0.7559078417975327\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "input_num = main_data[0][0].__len__()\n",
    "model = DenseNN(input_num)\n",
    "\n",
    "\n",
    "# # Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 30\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "  print(\"In epoch: \", epoch)\n",
    "  \n",
    "  running_loss_train = []\n",
    "  running_loss_val = []\n",
    "  \n",
    "  index = 0\n",
    "  \n",
    "  for batch in train_loader:\n",
    "      \n",
    "      index = index + 1\n",
    "      inputs, labels = batch\n",
    "      # labels = labels.view(-1, 1) \n",
    "      optimizer.zero_grad()\n",
    "      # print(labels)\n",
    "\n",
    "      # Forward propagation\n",
    "      outputs = model(inputs)\n",
    "      loss = criterion(outputs, labels)\n",
    "      \n",
    "      # Backward propagation and optimize\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      running_loss_train.append(loss.item())\n",
    "\n",
    "      if index % 10 == 9:    # Print every 100 mini-batches\n",
    "        print(\"batch: \", index, \" loss = \" , np.mean(np.asarray(running_loss_train)))\n",
    "\n",
    "  print(\"End train epoch, mean loss: \", np.mean(np.asarray(running_loss_train)))\n",
    "  index = 0\n",
    "  for batch in val_loader:\n",
    "      index = index+1\n",
    "      inputs, labels = batch\n",
    "      # labels = labels.view(-1, 1) \n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      outputs = model(inputs)\n",
    "      loss = criterion(outputs, labels)\n",
    "\n",
    "      running_loss_val.append(loss.item())\n",
    "      if index % 10 == 9:    # Print every 100 mini-batches\n",
    "        print(\"batch: \", index, \" loss = \" , np.mean(np.asarray(running_loss_val)))\n",
    "\n",
    "  print(\"End val epoch, mean loss: \", np.mean(np.asarray(running_loss_val)))\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model working at 78.9% accuracy\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "y_target = []\n",
    "y_pred = []\n",
    "for batch in val_loader:\n",
    "      \n",
    "      inputs, labels = batch\n",
    "      outputs = model(inputs)\n",
    "      loss = criterion(outputs, labels)\n",
    "      numpy_array = outputs.detach().numpy()\n",
    "      y_target.extend(labels.numpy())\n",
    "      y_pred.extend(numpy_array)\n",
    "\n",
    "\n",
    "y_target = np.array(y_target)  # Example true labels\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "pred_vals = [x.argmax() for x in y_pred]\n",
    "mask = pred_vals == y_target\n",
    "accuracy = mask.sum()/len(mask) * 100\n",
    "print(f'Model working at {accuracy:0.1f}% accuracy')\n",
    "\n",
    "\n",
    "target_labels = [\"Home Loss\", \"Home Win\", \"Draw\"]\n",
    "\n",
    "def plot_roc_curve(y_true, y_pred_prob):\n",
    "\n",
    "    # Binarize the labels\n",
    "    y_true_binarized = label_binarize(y_true, classes=[0, 1, 2])\n",
    "\n",
    "    column_sums = np.sum(y_true_binarized, axis=0)\n",
    "    # print(column_sums)\n",
    "    # print(y_true_binarized)\n",
    "    # print(y_pred_prob)\n",
    "\n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "\n",
    "    for i in range(len(target_labels)):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_true_binarized[:, i], y_pred_prob[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # Plot ROC curves\n",
    "    plt.figure()\n",
    "    # colors = ['blue', 'red', 'green', 'orange']\n",
    "    for i in range(len(target_labels)):\n",
    "        plt.plot(fpr[i], tpr[i], lw=2,\n",
    "                 label='ROC curve of {0} (area = {1:0.2f})'\n",
    "                 ''.format(target_labels[i], roc_auc[i]))\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve for 3-class Classification')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "plot_roc_curve(y_target, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the trained model for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'AFL_prediction_model_DNN.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DenseNN(16)\n",
    "model.load_state_dict(torch.load('AFL_prediction_model_DNN.pth', weights_only=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_nodes = 8\n",
    "output_nodes = 3\n",
    "\n",
    "class ConvNN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(ConvNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=2, kernel_size=2, stride=1, padding=1)\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=2, stride=2)  # Max pooling layer\n",
    "        self.conv2 = nn.Conv1d(in_channels=2, out_channels=4, kernel_size=2, stride=1, padding=1)\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=2, stride=2)  # Max pooling layer\n",
    "        self.conv3 = nn.Conv1d(in_channels=4, out_channels=8, kernel_size=2, stride=1, padding=1)\n",
    "        self.pool3 = nn.MaxPool1d(kernel_size=2, stride=2)  # Max pooling layer\n",
    "        self.fc = nn.Linear(in_features=8 * 24 * 24, out_features=4)  # Adjusted input size\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = self.pool1(x)  # Max pooling\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = self.pool2(x)  # Max pooling\n",
    "        x = torch.relu(self.conv3(x))\n",
    "        x = self.pool3(x)  # Max pooling\n",
    "        # x = x.view(-1, 8 * 24 * 24)  # Adjusted input size\n",
    "        x = self.fc(x)\n",
    "        return functional.softmax(x, dim=1)\n",
    "\n",
    "\n",
    "model = ConvNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNN()\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
