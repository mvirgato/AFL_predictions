{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AFL Match Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.style.use(['mvstyle', 'one_piece'])\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import libs.data_processing as dp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if data needs to be retrieved from the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.get_standings()\n",
    "dp.get_seasonal_data()\n",
    "dp.get_standings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine all seasonal data into one DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = dp.process_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "round             2.0\n",
       "hteamid          17.0\n",
       "ateamid           8.0\n",
       "hrank            17.0\n",
       "arank            11.0\n",
       "hscore_ppg       49.0\n",
       "ascore_ppg      136.0\n",
       "hgoals_ppg        7.0\n",
       "agoals_ppg       20.0\n",
       "hbehinds_ppg      7.0\n",
       "abehinds_ppg     16.0\n",
       "hwins             0.0\n",
       "awins             0.0\n",
       "hlosses           0.0\n",
       "alosses           0.0\n",
       "is_final          0.0\n",
       "hteamwin          0.0\n",
       "Name: 10, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data.iloc[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import libs.neural_nets as mnn\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process data for use in neural nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_data = mnn.PandasDataset(full_data)\n",
    "\n",
    "\n",
    "train_proportion = 0.7\n",
    "val_proportion = 1.0 - train_proportion\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "train_data, val_data = mnn.train_test_split(main_data, train_size=train_proportion, shuffle=True, random_state=42)\n",
    "\n",
    "train_loader = mnn.DataLoader(train_data, \n",
    "                          shuffle=True, \n",
    "                          num_workers=2, \n",
    "                          batch_size=batch_size\n",
    "                          )\n",
    "\n",
    "val_loader = mnn.DataLoader(val_data, \n",
    "                        shuffle=True, \n",
    "                        num_workers=2, \n",
    "                        batch_size=batch_size\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test speed of data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.010378611087799073 [s/iteration]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "tstart=time.time()\n",
    "num_iter=100\n",
    "ctr=num_iter\n",
    "for batch in train_loader:\n",
    "    ctr -=100\n",
    "    if ctr <= 0: break\n",
    "print((time.time()-tstart)/num_iter,'[s/iteration]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense Neural Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the neural network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch:  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch:  9  loss =  1.227190203136868\n",
      "batch:  19  loss =  1.1625134568465383\n",
      "batch:  29  loss =  1.1286624094535564\n",
      "batch:  39  loss =  1.1075608287102137\n",
      "batch:  49  loss =  1.0874322105427177\n",
      "batch:  59  loss =  1.0704359028298975\n",
      "End train epoch, mean loss:  1.0567057808833336\n",
      "batch:  9  loss =  0.9367124173376296\n",
      "batch:  19  loss =  0.9318839405712328\n",
      "batch:  29  loss =  0.9293567394388134\n",
      "End val epoch, mean loss:  0.9293567394388134\n",
      "In epoch:  1\n",
      "batch:  9  loss =  0.8990218506919013\n",
      "batch:  19  loss =  0.8724566164769625\n",
      "batch:  29  loss =  0.8467323677293186\n",
      "batch:  39  loss =  0.8229612738658221\n",
      "batch:  49  loss =  0.8023438940242845\n",
      "batch:  59  loss =  0.7883226800773103\n",
      "End train epoch, mean loss:  0.7768087262537942\n",
      "batch:  9  loss =  0.6979796820216708\n",
      "batch:  19  loss =  0.715046719500893\n",
      "batch:  29  loss =  0.7193501283382547\n",
      "End val epoch, mean loss:  0.7193501283382547\n",
      "In epoch:  2\n",
      "batch:  9  loss =  0.7514946990542941\n",
      "batch:  19  loss =  0.7348738626429909\n",
      "batch:  29  loss =  0.7236865306722706\n",
      "batch:  39  loss =  0.7161783209213843\n",
      "batch:  49  loss =  0.7092951402372244\n",
      "batch:  59  loss =  0.6991331112586846\n",
      "End train epoch, mean loss:  0.6915103775351795\n",
      "batch:  9  loss =  0.6497226622369554\n",
      "batch:  19  loss =  0.6448267102241516\n",
      "batch:  29  loss =  0.6525111547831831\n",
      "End val epoch, mean loss:  0.6525111547831831\n",
      "In epoch:  3\n",
      "batch:  9  loss =  0.6218596233261956\n",
      "batch:  19  loss =  0.6072834385068793\n",
      "batch:  29  loss =  0.5956453105499004\n",
      "batch:  39  loss =  0.5890484849611918\n",
      "batch:  49  loss =  0.5816771588763412\n",
      "batch:  59  loss =  0.5747974979675422\n",
      "End train epoch, mean loss:  0.5685481909495681\n",
      "batch:  9  loss =  0.5163743760850694\n",
      "batch:  19  loss =  0.5124875260026831\n",
      "batch:  29  loss =  0.5245700591597063\n",
      "End val epoch, mean loss:  0.5245700591597063\n",
      "In epoch:  4\n",
      "batch:  9  loss =  0.5324039227432675\n",
      "batch:  19  loss =  0.5250910300957529\n",
      "batch:  29  loss =  0.5256561544434778\n",
      "batch:  39  loss =  0.5164144352460519\n",
      "batch:  49  loss =  0.513430909842861\n",
      "batch:  59  loss =  0.5090385044025163\n",
      "End train epoch, mean loss:  0.5057012705660578\n",
      "batch:  9  loss =  0.5070988602108426\n",
      "batch:  19  loss =  0.5110459500237515\n",
      "batch:  29  loss =  0.5070939269559137\n",
      "End val epoch, mean loss:  0.5070939269559137\n",
      "In epoch:  5\n",
      "batch:  9  loss =  0.5002547966109382\n",
      "batch:  19  loss =  0.4959697535163478\n",
      "batch:  29  loss =  0.5025370758155296\n",
      "batch:  39  loss =  0.508509473158763\n",
      "batch:  49  loss =  0.5025552128042493\n",
      "batch:  59  loss =  0.4951586677866467\n",
      "End train epoch, mean loss:  0.49575073905845185\n",
      "batch:  9  loss =  0.5039681163099077\n",
      "batch:  19  loss =  0.5121865319578272\n",
      "batch:  29  loss =  0.5077788398183626\n",
      "End val epoch, mean loss:  0.5077788398183626\n",
      "In epoch:  6\n",
      "batch:  9  loss =  0.5297658112314012\n",
      "batch:  19  loss =  0.5134997430600619\n",
      "batch:  29  loss =  0.4978649790944724\n",
      "batch:  39  loss =  0.4951833838071579\n",
      "batch:  49  loss =  0.4931411104542868\n",
      "batch:  59  loss =  0.4946523586572227\n",
      "End train epoch, mean loss:  0.4922569692134857\n",
      "batch:  9  loss =  0.5228266417980194\n",
      "batch:  19  loss =  0.5172460188991145\n",
      "batch:  29  loss =  0.5036150843932711\n",
      "End val epoch, mean loss:  0.5036150843932711\n",
      "In epoch:  7\n",
      "batch:  9  loss =  0.49280134505695766\n",
      "batch:  19  loss =  0.4981599293257061\n",
      "batch:  29  loss =  0.4852323377954549\n",
      "batch:  39  loss =  0.4886089914884323\n",
      "batch:  49  loss =  0.4921696411103618\n",
      "batch:  59  loss =  0.493505457195185\n",
      "End train epoch, mean loss:  0.4895534693305172\n",
      "batch:  9  loss =  0.49994264708624947\n",
      "batch:  19  loss =  0.4993921612438403\n",
      "batch:  29  loss =  0.4998133233908949\n",
      "End val epoch, mean loss:  0.4998133233908949\n",
      "In epoch:  8\n",
      "batch:  9  loss =  0.5093232525719537\n",
      "batch:  19  loss =  0.5029731016410025\n",
      "batch:  29  loss =  0.5072726216809503\n",
      "batch:  39  loss =  0.49895739555358887\n",
      "batch:  49  loss =  0.49920271184979653\n",
      "batch:  59  loss =  0.49203843888589893\n",
      "End train epoch, mean loss:  0.49229645906989256\n",
      "batch:  9  loss =  0.5095623864067925\n",
      "batch:  19  loss =  0.506813174799869\n",
      "batch:  29  loss =  0.4957910252028498\n",
      "End val epoch, mean loss:  0.4957910252028498\n",
      "In epoch:  9\n",
      "batch:  9  loss =  0.5238562193181779\n",
      "batch:  19  loss =  0.523340493440628\n",
      "batch:  29  loss =  0.4999835583670386\n",
      "batch:  39  loss =  0.49431776389097554\n",
      "batch:  49  loss =  0.5012828586052875\n",
      "batch:  59  loss =  0.4993152623459444\n",
      "End train epoch, mean loss:  0.49183812959870293\n",
      "batch:  9  loss =  0.5253728396362729\n",
      "batch:  19  loss =  0.5173746723877756\n",
      "batch:  29  loss =  0.5092559631528526\n",
      "End val epoch, mean loss:  0.5092559631528526\n",
      "In epoch:  10\n",
      "batch:  9  loss =  0.48030564851231045\n",
      "batch:  19  loss =  0.4846393889502475\n",
      "batch:  29  loss =  0.49449394900223304\n",
      "batch:  39  loss =  0.49144601592650783\n",
      "batch:  49  loss =  0.49297155774369533\n",
      "batch:  59  loss =  0.4887438815529064\n",
      "End train epoch, mean loss:  0.49036759938766705\n",
      "batch:  9  loss =  0.5475287106302049\n",
      "batch:  19  loss =  0.5013996895990873\n",
      "batch:  29  loss =  0.4956243808927207\n",
      "End val epoch, mean loss:  0.4956243808927207\n",
      "In epoch:  11\n",
      "batch:  9  loss =  0.5119969149430593\n",
      "batch:  19  loss =  0.5078749170428828\n",
      "batch:  29  loss =  0.4916628506676904\n",
      "batch:  39  loss =  0.4814968277246524\n",
      "batch:  49  loss =  0.48583120898324617\n",
      "batch:  59  loss =  0.48859742738432804\n",
      "End train epoch, mean loss:  0.4901452589390883\n",
      "batch:  9  loss =  0.5141177210542891\n",
      "batch:  19  loss =  0.5041223387969168\n",
      "batch:  29  loss =  0.5022773413822569\n",
      "End val epoch, mean loss:  0.5022773413822569\n",
      "In epoch:  12\n",
      "batch:  9  loss =  0.4696392748090956\n",
      "batch:  19  loss =  0.4819028063824302\n",
      "batch:  29  loss =  0.4892717517655471\n",
      "batch:  39  loss =  0.4975691858010414\n",
      "batch:  49  loss =  0.4896294924677635\n",
      "batch:  59  loss =  0.4920135792029106\n",
      "End train epoch, mean loss:  0.4898779040841914\n",
      "batch:  9  loss =  0.531121058596505\n",
      "batch:  19  loss =  0.5013968709268068\n",
      "batch:  29  loss =  0.497379503373442\n",
      "End val epoch, mean loss:  0.497379503373442\n",
      "In epoch:  13\n",
      "batch:  9  loss =  0.46630094117588466\n",
      "batch:  19  loss =  0.4826139227340096\n",
      "batch:  29  loss =  0.4865180325919184\n",
      "batch:  39  loss =  0.48996129937661\n",
      "batch:  49  loss =  0.49402449629744705\n",
      "batch:  59  loss =  0.4861176099817632\n",
      "End train epoch, mean loss:  0.48720825074323965\n",
      "batch:  9  loss =  0.48903168241182965\n",
      "batch:  19  loss =  0.49789916527898687\n",
      "batch:  29  loss =  0.5001453777839397\n",
      "End val epoch, mean loss:  0.5001453777839397\n",
      "In epoch:  14\n",
      "batch:  9  loss =  0.48094216651386684\n",
      "batch:  19  loss =  0.4871014325242293\n",
      "batch:  29  loss =  0.48217684133299465\n",
      "batch:  39  loss =  0.47698274713296157\n",
      "batch:  49  loss =  0.4826326291171872\n",
      "batch:  59  loss =  0.4823606979038756\n",
      "End train epoch, mean loss:  0.4873514299962058\n",
      "batch:  9  loss =  0.5239630672666762\n",
      "batch:  19  loss =  0.5081074269194352\n",
      "batch:  29  loss =  0.49567709400736054\n",
      "End val epoch, mean loss:  0.49567709400736054\n",
      "In epoch:  15\n",
      "batch:  9  loss =  0.45913213822576737\n",
      "batch:  19  loss =  0.46714016167741074\n",
      "batch:  29  loss =  0.48423904899893133\n",
      "batch:  39  loss =  0.4810160918113513\n",
      "batch:  49  loss =  0.48782030781921076\n",
      "batch:  59  loss =  0.48604140544341784\n",
      "End train epoch, mean loss:  0.4840367116145234\n",
      "batch:  9  loss =  0.48601485623253715\n",
      "batch:  19  loss =  0.4747928239797291\n",
      "batch:  29  loss =  0.4971198388214769\n",
      "End val epoch, mean loss:  0.4971198388214769\n",
      "In epoch:  16\n",
      "batch:  9  loss =  0.47763238350550336\n",
      "batch:  19  loss =  0.47994241902702733\n",
      "batch:  29  loss =  0.4829918423603321\n",
      "batch:  39  loss =  0.4846187860537798\n",
      "batch:  49  loss =  0.4755572512441752\n",
      "batch:  59  loss =  0.47995275208505533\n",
      "End train epoch, mean loss:  0.4853621276456918\n",
      "batch:  9  loss =  0.5171407096915774\n",
      "batch:  19  loss =  0.4878987920911689\n",
      "batch:  29  loss =  0.4955815189871295\n",
      "End val epoch, mean loss:  0.4955815189871295\n",
      "In epoch:  17\n",
      "batch:  9  loss =  0.46755172808965045\n",
      "batch:  19  loss =  0.4761401571725544\n",
      "batch:  29  loss =  0.4676508667140171\n",
      "batch:  39  loss =  0.4718201160430908\n",
      "batch:  49  loss =  0.48028076120785307\n",
      "batch:  59  loss =  0.48215172856541005\n",
      "End train epoch, mean loss:  0.48397673866642055\n",
      "batch:  9  loss =  0.47237910164727104\n",
      "batch:  19  loss =  0.48646581172943115\n",
      "batch:  29  loss =  0.4924879937336363\n",
      "End val epoch, mean loss:  0.4924879937336363\n",
      "In epoch:  18\n",
      "batch:  9  loss =  0.4783293439282311\n",
      "batch:  19  loss =  0.471308370954112\n",
      "batch:  29  loss =  0.4792687903190481\n",
      "batch:  39  loss =  0.48264461068006664\n",
      "batch:  49  loss =  0.4855222221539945\n",
      "batch:  59  loss =  0.4834896038144322\n",
      "End train epoch, mean loss:  0.4839073295023904\n",
      "batch:  9  loss =  0.5021865136093564\n",
      "batch:  19  loss =  0.49606134546430486\n",
      "batch:  29  loss =  0.49212232026560554\n",
      "End val epoch, mean loss:  0.49212232026560554\n",
      "In epoch:  19\n",
      "batch:  9  loss =  0.46939747201071846\n",
      "batch:  19  loss =  0.4679908877924869\n",
      "batch:  29  loss =  0.4631378547898654\n",
      "batch:  39  loss =  0.47602688272794086\n",
      "batch:  49  loss =  0.47533897964321836\n",
      "batch:  59  loss =  0.4810706387131901\n",
      "End train epoch, mean loss:  0.4854748587110149\n",
      "batch:  9  loss =  0.5250366727511088\n",
      "batch:  19  loss =  0.49433961510658264\n",
      "batch:  29  loss =  0.4941334128379822\n",
      "End val epoch, mean loss:  0.4941334128379822\n",
      "In epoch:  20\n",
      "batch:  9  loss =  0.47520049744182163\n",
      "batch:  19  loss =  0.4871512494589153\n",
      "batch:  29  loss =  0.49176602322479773\n",
      "batch:  39  loss =  0.4917690585821103\n",
      "batch:  49  loss =  0.4900986071752042\n",
      "batch:  59  loss =  0.4813150672589318\n",
      "End train epoch, mean loss:  0.4855822760667374\n",
      "batch:  9  loss =  0.5021243823899163\n",
      "batch:  19  loss =  0.5106619659223055\n",
      "batch:  29  loss =  0.5024680896051998\n",
      "End val epoch, mean loss:  0.5024680896051998\n",
      "In epoch:  21\n",
      "batch:  9  loss =  0.48058056169086033\n",
      "batch:  19  loss =  0.49092006055932297\n",
      "batch:  29  loss =  0.4802193312809385\n",
      "batch:  39  loss =  0.48156352990712875\n",
      "batch:  49  loss =  0.47943398843006213\n",
      "batch:  59  loss =  0.4839347439297175\n",
      "End train epoch, mean loss:  0.4830896209425001\n",
      "batch:  9  loss =  0.5270816915565066\n",
      "batch:  19  loss =  0.5020539133172286\n",
      "batch:  29  loss =  0.49042299287072544\n",
      "End val epoch, mean loss:  0.49042299287072544\n",
      "In epoch:  22\n",
      "batch:  9  loss =  0.5102700756655799\n",
      "batch:  19  loss =  0.4918386544051923\n",
      "batch:  29  loss =  0.4984641445094141\n",
      "batch:  39  loss =  0.4880996040808849\n",
      "batch:  49  loss =  0.4815752956331993\n",
      "batch:  59  loss =  0.48120879571316605\n",
      "End train epoch, mean loss:  0.484282562092169\n",
      "batch:  9  loss =  0.4916534920533498\n",
      "batch:  19  loss =  0.507899632579402\n",
      "batch:  29  loss =  0.5033737852655608\n",
      "End val epoch, mean loss:  0.5033737852655608\n",
      "In epoch:  23\n",
      "batch:  9  loss =  0.459077861573961\n",
      "batch:  19  loss =  0.4684695993599139\n",
      "batch:  29  loss =  0.4695504718813403\n",
      "batch:  39  loss =  0.4811822091921782\n",
      "batch:  49  loss =  0.48715671471187044\n",
      "batch:  59  loss =  0.4870432408179267\n",
      "End train epoch, mean loss:  0.4839693672621428\n",
      "batch:  9  loss =  0.46411609649658203\n",
      "batch:  19  loss =  0.47751216668831675\n",
      "batch:  29  loss =  0.4891722243407677\n",
      "End val epoch, mean loss:  0.4891722243407677\n",
      "In epoch:  24\n",
      "batch:  9  loss =  0.46588804986741805\n",
      "batch:  19  loss =  0.49683113945157903\n",
      "batch:  29  loss =  0.483068041760346\n",
      "batch:  39  loss =  0.4848336248825758\n",
      "batch:  49  loss =  0.4841158189335648\n",
      "batch:  59  loss =  0.48073328551599537\n",
      "End train epoch, mean loss:  0.4819119505917848\n",
      "batch:  9  loss =  0.46046602063708836\n",
      "batch:  19  loss =  0.4878614670351932\n",
      "batch:  29  loss =  0.4971979558467865\n",
      "End val epoch, mean loss:  0.4971979558467865\n",
      "In epoch:  25\n",
      "batch:  9  loss =  0.4849323464764489\n",
      "batch:  19  loss =  0.4903890976780339\n",
      "batch:  29  loss =  0.4874269263497714\n",
      "batch:  39  loss =  0.48571425905594456\n",
      "batch:  49  loss =  0.4859223280634199\n",
      "batch:  59  loss =  0.48488595677634416\n",
      "End train epoch, mean loss:  0.48379759868579125\n",
      "batch:  9  loss =  0.49674704008632237\n",
      "batch:  19  loss =  0.49357399501298604\n",
      "batch:  29  loss =  0.49884203898495644\n",
      "End val epoch, mean loss:  0.49884203898495644\n",
      "In epoch:  26\n",
      "batch:  9  loss =  0.486892388926612\n",
      "batch:  19  loss =  0.49307411752249064\n",
      "batch:  29  loss =  0.48271087120319234\n",
      "batch:  39  loss =  0.49016828949634844\n",
      "batch:  49  loss =  0.4915925240030094\n",
      "batch:  59  loss =  0.4897436039932704\n",
      "End train epoch, mean loss:  0.4829188509663539\n",
      "batch:  9  loss =  0.4740067720413208\n",
      "batch:  19  loss =  0.49363670851054947\n",
      "batch:  29  loss =  0.4909647137954317\n",
      "End val epoch, mean loss:  0.4909647137954317\n",
      "In epoch:  27\n",
      "batch:  9  loss =  0.4901112483607398\n",
      "batch:  19  loss =  0.4906629825893201\n",
      "batch:  29  loss =  0.4800757611620015\n",
      "batch:  39  loss =  0.4874369952923212\n",
      "batch:  49  loss =  0.48869696077035396\n",
      "batch:  59  loss =  0.4878714564493147\n",
      "End train epoch, mean loss:  0.48511957944329104\n",
      "batch:  9  loss =  0.4821895592742496\n",
      "batch:  19  loss =  0.49763616448954534\n",
      "batch:  29  loss =  0.49413491528609704\n",
      "End val epoch, mean loss:  0.49413491528609704\n",
      "In epoch:  28\n",
      "batch:  9  loss =  0.5475302570395999\n",
      "batch:  19  loss =  0.4942646340319985\n",
      "batch:  29  loss =  0.4901070810597518\n",
      "batch:  39  loss =  0.4877207325055049\n",
      "batch:  49  loss =  0.4808712206324752\n",
      "batch:  59  loss =  0.48081068770360136\n",
      "End train epoch, mean loss:  0.4814620338269134\n",
      "batch:  9  loss =  0.49775951438479954\n",
      "batch:  19  loss =  0.49573815653198644\n",
      "batch:  29  loss =  0.4911666101422803\n",
      "End val epoch, mean loss:  0.4911666101422803\n",
      "In epoch:  29\n",
      "batch:  9  loss =  0.5256458852026198\n",
      "batch:  19  loss =  0.5073997394034737\n",
      "batch:  29  loss =  0.48906928814690687\n",
      "batch:  39  loss =  0.49144780253752685\n",
      "batch:  49  loss =  0.4834080107358037\n",
      "batch:  59  loss =  0.48154609738770177\n",
      "End train epoch, mean loss:  0.48409924889678385\n",
      "batch:  9  loss =  0.507702949974272\n",
      "batch:  19  loss =  0.48418062611630086\n",
      "batch:  29  loss =  0.491389669221023\n",
      "End val epoch, mean loss:  0.491389669221023\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "hidden_nodes = 10\n",
    "output_nodes = 3\n",
    "hidden_layers = 3\n",
    "\n",
    "input_num = main_data[0][0].__len__()\n",
    "model = mnn.DenseNN(input_num, hidden_nodes, output_nodes, hidden_layers)\n",
    "\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 30\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "  print(\"In epoch: \", epoch)\n",
    "  \n",
    "  running_loss_train = []\n",
    "  running_loss_val = []\n",
    "  \n",
    "  index = 0\n",
    "  \n",
    "  for batch in train_loader:\n",
    "      \n",
    "      index = index + 1\n",
    "      inputs, labels = batch\n",
    "\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      # Forward propagation\n",
    "      outputs = model(inputs)\n",
    "      loss = criterion(outputs, labels)\n",
    "      \n",
    "      # Backward propagation and optimize\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      running_loss_train.append(loss.item())\n",
    "\n",
    "      if index % 10 == 9:    # Print every 100 mini-batches\n",
    "        print(\"batch: \", index, \" loss = \" , np.mean(np.asarray(running_loss_train)))\n",
    "\n",
    "  print(\"End train epoch, mean loss: \", np.mean(np.asarray(running_loss_train)))\n",
    "  index = 0\n",
    "  for batch in val_loader:\n",
    "      index = index+1\n",
    "      inputs, labels = batch\n",
    "      # labels = labels.view(-1, 1) \n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      outputs = model(inputs)\n",
    "      loss = criterion(outputs, labels)\n",
    "\n",
    "      running_loss_val.append(loss.item())\n",
    "      if index % 10 == 9:    # Print every 100 mini-batches\n",
    "        print(\"batch: \", index, \" loss = \" , np.mean(np.asarray(running_loss_val)))\n",
    "\n",
    "  print(\"End val epoch, mean loss: \", np.mean(np.asarray(running_loss_val)))\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model working at 78.2% accuracy\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAEICAYAAAC6fYRZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAA8M0lEQVR4nO2deXhU5fn3Pw/I4j5ErHWPEwERsTgJuBT3CXazFk3AlxbaYkkiIkRQAq4gKiSCgkVgovy8bP1pIdHaiktJ7ItC0RqIrwtLLRmWUtcaAopFtuf9Y86ZnJnMJDPJzJwzk/tzXXNlzvY89zkz+c597vM896201giCIAiZSRe7DRAEQRCSh4i8IAhCBnOE3QYIsaOUcgPlgBvwGatzAJ/W2m/Zz2Ps0wS4gCatdW1YWx5gJFBnrPIDXq11RSv9x31MojFsyANytdbFqerX0r+XwPXOSVL7Ea8xUJ/kfqcafbi01tXtbMOltW5KqGFCx9FayyuNXkABgX92c9kN7LIse4HysGOmAgVh+1SF7eMB1rfSb9zHJOn8qwgIUSKuowcoAoriPLYmSefW6jVOZL9Ag+W9D3Bb3rfr+ka6jtZ+5GXPSzz5NEdr7VdKuSyrWnh7WusKpVQDYHpoPiA3bJ96pVSItx9Ge45JBi7dQW/RuF7Ttda5QL1SahdQmQDbOkoqr7G1H7c27gR1x+6Oiml5HXMj7SikDonJpzFKKZdxm11oLLtb2b1JKeU194kilL4I62jrGKWUx/gRQSnlVkqtN8IaKKUKlFINRt9Vhs0FSqldRmgCY325UqrI2G9q2A+XaYcHyDL2c1va95p/o/VpbUdr3WQIvHlu66JdNKOtAuMcPRG2e41XudmPcQ28xjHl0dbFc40T2a9xHust792W81xvPc9I5x+lby9gfrae8H4sbYV/Vl7zu2C8j/gdFDqA3bcS8orvRSDMUEXg1r6I0NBNAVHCJ0CNsX/Ufdros9VjsIQSCISHvGF9ezBCAsa6KppDBF5je7mx7LKeVyv9eICpluVgqCFSnxHa8hq2uqJs95h2WG0Ks8Fnacu0v9xiR0G0dR28xh3qN6wt6/tywNPG+bfo21huYb/ZdiyflaV/b3g78mr/Szz59KRRa12rta4k4KEXGev9BGL0kXAb2+sJ/MO2IJL3bNCeY6xkaa3rteXhMIF/cmtoYCTwpeWhcWt3JSbFhm0mDQSEJ1qfIejAw+h6Aj9+kRhJQIDQAe+/RSgjbJ3L+LsMWG94pf5W1lmJ6xonsN/WiHj+Ufpui9Y+Kyy2fRmnjUIbiMinPw1APgTitxBVeLOMHwZ/K/vkReqgPceE0RihzVrADB+tIyAW9YYw12ut82NoNxJZ0fqMhGHHdCNc4DPCO1VthL6CGCELb1h/fgKx6BoCdyzR1lntiOsaJ6rf9hClb+v2mK4dzZ8VWkblJA0R+fQjK2y5EcPrNf65Cgnc8gYxYrFlllXFwBNh+7hoXRjbOqbJIlCDic3DW0cghNBEQICCwh4p/h2BKgJhAJPBQJsPKY2YvvUaNULAQ9VaFxovPwEvOKpNxh3Ul9oyPNXYp8jwfKsBM24daV04MX0uSeg3Gi3Ov5W+sdgZSeTb9VkJHUdG16QRxj9TLoGHj17DM69WShUrpQoAv9a6VillCoGfgNjWWP8pjX0aVeChrZ/AePpG804gEjEc4wNGKKX8BP7Zi1VgVEgekKeUKjLCS1Z8xnazfbf5QI4IPziWh4RTgcqwY1wY8wWM5Wh9Aiw3tpvPAnyRzl0HRrasN65tE+C32FBEQKTKwrzaLMPWAuM6+bXWTcZnErIunmucyH7D2vKb18po12Ncy+JI599a3wQewpttWj+vIq11ZZTPyvqZVhP4UclRSq0T7z4xKK0ld40gCEKmIuEaQRCEDEZEXhAEIYMRkRcEQchgROQFQRAyGBF5QRCEDMYRQyh//OMf68GDB7f7+G3btpGdnd0hGzKlDSfY4JQ2nGCDU9pwgg1OacMJNiSijZkzZ76itf5xmzvanVdBa83ll1+uO8J9993XoeMzqQ0n2OCUNpxgg1PacIINTmnDCTYkog1gle4suWuuuOKKjGnDCTY4pQ0n2OCUNpxgg1PacIINTmkjFkTkHdaGE2xwShtOsMEpbTjBBqe04QQbnNJGLGSEyAuCIAiRcYTId/QBRibhBE/HKci1aEauRTNyLYJsi2UnEXmHIV/gZuRaNCPXohm5FkG2xbJTQkTeKOdV08Z2r6W4hSAIgpACEiLyOpCrOiJGmlKzOINZC1IQBEFIAamYDDWYQPEBCOSZ9iDFAgRByBRGl8Drb8a06/xpj/GB59K4mp/UMI3z9/w9uHzg0GEe/b+fxHx8KkTeFbZ8QvgO27ZtY8aMGSHrrrjiCom9CUJnIA6RbA/tEda4KF4QWq04wVgFHmD3fw9RXvsxQHYsx6dC5JtoWbIuhOzs7BYiLwhCGpIAwU66KNvMwF5dKB3QLfYD3oUv9x7g2Ml/o3v37vQGnuj3AjfccMO2WA5PhcjX0ezNuzGqvwuCkMZYxDxElJPs1baXuIXVIWitefrvn3P7i9uZfHgud955JwDXX399zG0kROQtNTULzIewSqkarXW+DtQgnWrWdtSWWqOCIDiD+RsO8MGuw7EfkGQxT1dRTiSbNm2ipKSEN99sAGDt2rVorVFKxdVOQkTeEO5eYevyLe8rjLci8IKQIuIW7g4gopw4vvnmGx588EEefvhhDhw4wInHHMEjw7P5+dMvxS3w4JBUw4IgtBMjbJKIOPbA+tWUzpkIV18Gv1+SIAOFePj4448ZOnQoW7duBaC4uJjZZ9XT66gjoB0CDyLyguBs2hLxNsImA+tXU1pXHZtoD/XCxI3tt1XoMCeffDJnnHEGxxxzDD6fj4svvhh+e0mH2hSRFwQHEDW0EkfsO2LIZKgXkPmHTuXQoUMsWrSIH/7wh5x99tkopVi+fDm9evWiW7fEhL9E5AUhhXQkTi5x7zTkz1Ng+1sRN63b8TUly/ys/9de8vsdz1/G90cpxXcSbIKIvCAkig7Gx+MKrQjpQQSB3/3fg9z98r94fPWnaA2n9+rOLZd+t/WHqmde3G4THCHy5oxXmeUqpAvz/7eeD84cELoyxtBK1AecElrJXG4NDH+sqqqitLSUTz75lK5du1JaWsqMGTM45phjYm5q1apVrFq1CmKc8aoCpQLtZcaMGVpmvApOJKKYx4CEVgSg+aHprWvZsWMHffr0Yf/+/Vx00UUsWbKE733ve+1uWik1U2s9o639HOHJC4LdRI2VtyLwA7dvoPTnniRaJaQ7+w8epltXhQLOOOMMHnzwQY499ljGjRtHly6pKechIi90WmJ9CBpVzIeKwAvReeONNygpf597rjmVUca622+/PeV2iMgLGUl7RrEEY+UQGi8XMRfi4IsvvuCOO+7g6aefBmDJ3z7j/7QjHUGiEJEX0pqOTt1v8RBUJgMJ7eTw4cM89dRTTJ06lcbGRnr06MGdV53IVO+ptgk8iMgLaUjMYRarZx6OKeoyy1Noi1bGupt8vHs/I5/6iDX+rwDw9jueRYVn0ec7R6bCwlYRkRfSgtaEPSYxF4T20obAA5xw1BF8/vUBTjq2G49en82NnhOavfcOjHFPBCLygiNpy1tvIewi5kKyuXVtyOKrr77KhRdeSFZWFj2AF67ZwKmnnorL5bLFvGiIyAuOIS5hv/oy+FjCLELq2blzJ6WlpTz//POMGzeOyspKAAYMiH8+RSoQkRdSSjwPSqOGYcRrF2zg4MGDLFy4kHvuuYevv/6ao48+mnPPPddus9rEESIvaQ0ynw49LBVRF2zmne1fUTJkCO+++y4Aw4cPZ8GCBZx++ukpt0XSGgiOIZqwB6f8Ryv6LKIuOIiGez30feBdDuvArNWFCxdy7bXX2m2WpDUQUk+bMfXtGyi94xetNyICLziMnBN7Mvai75B16a+49957Ofroo+02KS5E5IUOEfcomHBE1AWHsWXLFiZMmMBdd93FpZcGUkZX3uhGTSy32bL2ISIvtIuooZi2vHURdcFJWCY6fXvgMBWvf8yDK3fy7UHNN1vW8uak8wBsnbHaUUTkhZhodTJSa8Iuoi44GUPg/+9Hu7l5uZ9/fL4PgF8OOZGHrzuzeT+bJzR1BBF5ISrtjrGLsAtpwpd7D3DbC9v4fd1/AOjXrx9LlizJqFF+IvJCC1odFTPnVhkRI2QMWsMrG5vo2bMnd999N7fffjs9evSw26yEIiIvBIkk7iEVjiINeRRxF9KMDRs20KdPH7p3707vY7rx7Jg+5Ex5iZycHLtNSwoi8p2cqF67JP0SMoy9e/cyc+ZMHnnkEe6//37uvPNOAIb1d0GGCjw4RORlxqs9RPTcZXSMkIG89NJLTJgwgR07dqCUYteuXXab1G7infHqCJHPzs5GZrymjnBxjzgDVcRcyAB27NjBpEmTePHFFwHweDz4fD7y8vLsNawDmM7wzJkzt8WyvyNEXkgNET13yRUjZCibNm1i8ODB7N27l2OPPZYHHniA8ePHc8QRnUv2OtfZdkLijrmLwAvtJYYKSqnkHK3JO7krJx6TxfzrszlV/QEW/8Fus1KOiHwGElcVJRF1IVHYLPC7vjnI3St2cNuVJ3P2iUeilOKVknM4qnvX1g9M44lOsSAinyHELOxSbENINmEVlJKN1ppnn32WyQ9M5vPPP2fbcbm8/PLLAByVUkuciYh8BtBqrN301KVYtZCBfPTRR4wfP57XX38dgKFDh1JRUWGzVc4iISKvlCoAmgC31roy3u1C+7EKvAi70FnYt28fc+bMYfbs2ezfv58TTjiBhx9+mF/+8pd06dLFbvMcRYevhiHgaK1rjWVv2HYv4De2+5VSno72KTQTVeAFIYPZsWNHUODHjh3L5s2b+fWvfy0CH4FEePKDgWXGez/gAWot29cB65VShQQ8+VqEDhMeohGBFzKdL7/8kqysLJRS9O3bl8cee4z+/ftz2WWX2W2ao0nEz54rbPkE64LWugnwAVVAbgL6E0aXhE5m2r4h8DBVBF7IQA4fPsySJUvIycnhueeeC64vLi4WgY+BRHjyTUBWtI1GuKZWa12hlCpXShVoraut+5hpDaxIioMIjC5h/uACPiheEFy11DdJxF2wnz9PSUqz7733HsXFxfz9738HYOXKlYwaNSopfTkZSyoDK9mxHJsIka+j2Zt3AzVh2z1aa/Nx92xgRHgDktagDYx0A/OnPcYHnkuDqwf26iICLzgDc4x8gsacf/3119x3330sWLCAQ4cOccopp7BgwQJuuOGGhLSfbkRyelOW1kBrXa2Ummp47C7LA9garXU+UKmUKiIQr5fRNe0hTOBD0v8KgpP46bwON7Fx40auueYadu7cSZcuXZg4cSKzZs3iuOOOS4CBnY+EDKG0eOq1lnX5xt8mQIS9PZjhmeXvBleJwAuZTk5ODkcddRR5eXksWbKE3Fx5lNcRZDKUQ5n/v/UhsXcQgRcykwMHDvD4448zZswYsrKy6NGjBzU1NZx66ql07dpGSgKhTUTkHUZwaOSZA4LrRNyFTGXt2rWUlJTwwQcfsGnTJnw+HwBnnHGGzZZlDiLyDqJFnvftGyj9ucwdEzKPxsZGpk2bxhNPPAGA2+1m+PDhNluVmYjI20zUvDN11TJyRsg4tNY888wzTJkyhS+++IJu3boxdepU7rrrLo488ki7zctIRORtRARe6GzU19czZswYAC6//HIWL15M//79bbYqsxGRt4mIicVAUhMI7cNhBTusHDx4MFiNKTc3l9tuu43vfe97jBkzBqWUzdZlPo4Q+c5UyLtF3F0SiwmJwAkCH2Ei1MqVK5kwYQJLly7l0ksD8zweeeSRVFuWUcRbyFtprZNpT0zMmDFDd4YZryLwQtL47SWBvyku2BGNTz75hMmTJ/OHPwTK7RUWFrJ8+XKbrcoslFIztdYz2trPEZ58Z0HCM0Kmc+jQIXw+H9OnT2fPnj0ceeSRzJgxg9tuu81u0zotIvIpYv7/1gfHvov3LmQiW7ZsYdSoUdTV1QHw4x//mIULF5KdnW2vYZ0cybCfTEaXwCnnMv+xWj4wBH5g/WoReCEjcblcNDQ0cOqpp/LCCy/w0ksvicA7APHkk0WEtMADt2+gdKIX8EY/ThDSBK01L7/8MsOGDaN79+707t2bl19+mQEDBnDsscfabZ5gENGTV0qNU0otVkoNUkodr5S6KtWGpTWmwIelBZbZq0KmsHXrVn7yk59w7bXXMnfu3OD6iy66SATeYUQL1zRorW8mMPpmdyoNSnuM3O/WtMBLh/aQ3DNCRrB//37mzJnDgAEDeOWVVzj++OM56aST7DZLaIVo4ZpcpVQj0Mvw4j3AX1NnVppiKe5hIuIuJI0UT4Bas2YNJSUlbNiwAYBRo0Yxb948vvvd76bMBiF+ool8JTCdgLiv1FrPjbKfYBKhetPAXvJcW0gi4QKfoKpMkfjb3/4WnMx09tlns2jRIvLz85PWn5A4Ioq8EaKZBqCUukApdZzWek+yjEjrGa+GuANSvUmwhxRMgLrkkksYNmwYF198MdOmTaNnz55J71OITLwzXqM9eA0+aNVavwvkJcC2qJg1XkXgBcEZbNq0iWuuuYYtW7YAoJTi1VdfZcaMGSLwNnPFFVeYNbG3xbJ/iCevlLoByAfylFINgAI0gfqsEpM3sYg7wPyHn2keBy8CL6Qx33zzDQ8++CAPP/wwBw4c4O677w6mJujSRcKP6UiIyGutn1dK1RIouP1ulGM6NyLwQoby2muvMX78eLZu3QpAcXExs2fPttkqoaO0+GnWWu8OF3il1PWpM8nBWAX+6suYX/OeCLyQ9nzyySeMGDGCH/7wh2zdupWBAweydu1alixZQq9evew2T+ggER+8KqWuBsoIhGoU0AC8kEK7nIc1/m5672bCMRF4IY3Zs2cPf/rTnzj66KOZOXMmEydOpFs3+T5nCtGGUJ6ltR6mlDreWHanyiDHYvHgP5Ai2+mHg4tq2MGmTZs455xzUErRr18/fve733HxxRdLAe0MJNqTlK1Kqd8YQymLgNwU2uQ8Rpc0v7ckFpOZrGlEpgp8nGPjd+/eza233sqAAQN49tlng+tHjhwpAp+hRBsn/7pS6ixj8R3gzNSZ5CAiPWRd862NBgkdxiFFNVKN1pqqqipKS0v55JNP6Nq1K9u3b7fbLCEFRM1CqbXeavx9o9MmKLMIfKQwjSCkAw0NDdxyyy385S9/AQJJxHw+H+eff77NlgmpIHyc/NVADVAOzAbuBC4wNneucfLWEM3HG5m/4UDwQevSoT1sMkoQ4mP16tUMGzaMffv24XK5KC8v5ze/+Y2Mee9EhHvyF2ituxiTosqBWqBGa/16Mo1wXFqD8KGSltqs4sEL6cSQIUM444wzGDJkCHPnzpWMkRlAhwp5K6Vu0Fo/b7y/2hT3ZOeucVwh71POBUInOoGMpElrHFboOll88cUXzJw5k/vvv5+srCwgMETyuOOOs9kyIdG0t5C3mc4A4Cyl1CDjvRfoHJkojTDN/GmPicALacPhw4d56qmnmDp1Ko2NjRw8eJAlSwIjwUTgOzfhIp9PYEy8MpaHGX81nYEo6YJF3AUn8+GHH3LzzTezZs0aALxeL1OmTLHZKsEphIv8uEg5a5RSF4Svy0hE4NOXTjjZae/evcyaNYt58+Zx8OBBTjrpJB599FFuvPFGlFJtNyB0CsITlEVMStYZkpXN33CAD5Y3n6YIfJoRi8AnsaiGHaxfv57y8nKUUowfP54HH3wQl8tlt1mCw4g6Tr6zYY6eARH4tCbDH6zu3r2b448PZBu57LLLmDVrFvn5+Vx44YU2WyY4lYSMB1RKFSilvEqpoijbPcY+BYnoL9HM33Ag+H6pb5IIvOA4Dh48yPz58zn99NNZvXp1cP3dd98tAi+0SodF3hRurXWtseyNsNt0rXU1kKWUclyys+AY+PrVIblpBMEJvPPOOwwZMoTbbruNr776ipdeesluk4Q0Ilr5v3FKqcVKqUFKqePbSGswmEDlKIy/nrC2ioA6pZRba12ptfaHN2AnVi++tK7aRksEIZSmpiZuueUWLrroIt59913OPPNMXnrpJSoqKuw2TUgjosXk/VrrJ5RSF2itd7fxpN4VtnxC2HKO8bdRKeUDyrTWTdYdzBmvVlIx+zVkJqt48YKDeOuttxg+fDifffYZRxxxBFOmTOGee+7h6KOPtts0wQYss1ytZMdybDSRv0Ap9SXQy/DiPUTPXdMEZLXRT4PWukkptZ5A6uIQV8Qs5J1KwgU+4MVHijQJQurp06cPBw8e5Pvf/z6LFy9m4MCBdpsk2Egkp3fmzJnbYjk2msifB/QmIO4rtdatzXato9mbdxNIcBa+3fwRcBH4UbCVFgI/ZyJ8vNFmq4S4yaCx8d9++y0+n4+SkhK6d+9O7969eeutt8jJyZFkYkKHiPbt+T2wjOYkZVExHqi6jQeuLssD2BrLdpf5QFZrXZkg29tFRIG/+jI7TRLaS7jAp+k4+L/+9a+cf/75TJo0iblzm/2pPn36iMALHSaaJ1+ntd5jpB6+Uyn1pdb65miNaK3N8EutZV1+a9vtIijw2zcEBB4kFp/upOnY+M8//5wpU6bwzDPPAHDOOefw/e9/32arhEwjmsj/1YjJVxFIdbA7hTYljZCRNHf8IvBGvHghxRw+fJgnn3ySsrIympqa6NmzJ3fffTd33HEH3bt3t9s8IcOIJvKzzZTDmUJImGb7huYN4sULKWbFihUUFxcDcM011/D444+Tk5PTxlGC0D6i1XgNEXilVLbWeltKLEoS1qIfpSPEixdSy+HDh4Px9WuvvZYbb7yR4cOHU1hYKMnEhKQS8lRHKbXM+LtSKbXMeC2n5YiZtKV0zq3NC+LFCyngz3/+M/3792fLli0AKKV47rnnGDFihAi8kHTCH91PM/6Waa1HGq8RwIgU25VQrLF4a1k/QUgmO3bs4Gc/+xnXXXcdH330Eb/97W/tNknohISIvNZ6q/E3mHPXqA7VQBIxZ7xGmNHVYVrMaoWAwIsXLySJAwcOMG/ePM4991z+9Kc/ceyxx7JgwQIeeeQRu00TMoBVq1aZk0ezY9k/pMZrcKVSV2mt/xptOdEks8brTWu+BYwhk+aIGpn4lH60NvHJQUMo33vvPcaMGcP7778PQGFhIY8++iinnnqqzZYJmUa7arwqpW4gUALQrPWqCJT+8xM9rYFjkSGTGUQ0gXfYBKiePXuyefNmzjrrLBYuXMiPfvQju00SOjnhlaGeV0rVAu5MqAYlYZoMxEFeO4DWmpUrVzJs2DCUUvTr14+XX36ZSy65hKOOOspu8wShZVoDrfXucIFXSmWnzKIEEeLFy8xWIQn84x//wOv18oMf/IDnnnsuuN7r9YrAC44hPFyzTGs9Uim1EthlrgYuAPqk2riOEHHikyAkgH379jF79mzmzJnD/v37OeGEE+jatavdZglCRMInQ1mHUFpH2FyQOpM6jsTihWRRW1vLzTffHBzzPnbsWMrLy+ndu7fNlglCZMJj8luNt72MEI2LQJL1tCqZJLF4IRk8//zzFBQEyhSfe+65LF68mMsuE+dBcDbRcte4tNbblFL/BHIJ5IlPC1rE4kXghQTxk5/8hEGDBjFy5EgmT54sycSEtCBasurdRkWod7XWe0gjkW/hxYvAC+3kvffe49prr6WxsRGAHj16sG7dOqZNmyYCL6QN0US+kcB4+d8YY+eHpM6kxCDFQDKEP0+B316S0i6/+uorpkyZQm5uLitWrOChhx4KbpMHrEK6ES0L5btKqTzgCQIFRKZF2i9RmGkNOlq8OyRHDYgXnwlYJ0EleeKT1poXX3yRiRMnsnPnTrp06cKkSZO49957k9qvIMSDpah3diz7RxR5pdQ4ArNcpxEo7Xd7G3VeO0SiCnm3CNUImUOSJ0Ft376dCRMmsGLFCgDy8vJYsmQJubm5Se1XEOLFdIY7Wsh7nWUI5dZ0SIca8YGrIMSI3+9nxYoVHHfccTz00EOUlJRIaEbICKKJfJ5SSgNNBB66XgC8niqj4iVipkkJ1Qht0NDQEKzIdOWVV7J48WJ++tOfcsopp9hsmSAkjogPXrXWTxB48FoJ5CczVNNRwsv6BVMYCEIUGhsbGTduHH369GHNmjXB9SUlJSLwQsbRQuSVUscppY7TWj+stR6mtZ5uh2GxEiLwMrtVaAWtNb/73e/o168fTz75JEcccQQffvih3WYJQlIJL/93A7CNQBz+elssaichAi+hGiGMzZs3c9VVV/HLX/6S//znP1x++eW89957lJSU2G2aICSV8Ji8W2udBcERNo6mxZBJEXjn0FqRjxTz4osvMmLECA4cOEDv3r2ZN28eo0ePlvqqQqcgXOT9kd4b4Zs9qTEpdkIetorAO4tECnwHx8cPHTqU448/nuHDhzNnzhyysrISZJggOJ9wkT/LqOka/n4k4KjYfIshk1LSz5nYUOTjk08+Yd68eTz00EN0796d3r17849//EPEXeiUhIv8jcBgAjnkAYYZf88iiSLfnhmvMvFJCOfQoUMsWbKEO++8kz179nDCCScwfXrgaysCL2QKHZ3xOi5S2b9k55PvyIxXmfgkANTX11NSUkJdXR0QyBg5atQom60ShMQT74zXkNE10eq6Oq7e62jLiAiJxXdq9uzZQ2lpKYMHD6auro7TTjuNF154gT//+c+ceeaZdpsnCLYTLQuls3n9zeb3IvCdmpdeeokFCxaglGLy5Mls3LiR4cOHy8gZQTCIltbA0cyf9pjdJgg2snfvXo4++mgARo0axTvvvMOvf/1rBg0aZK9hguBAInrySqlxSqnFSqlBSqnjjQIizmB0CR94LgVgYK/0vBER2sf+/fuZPXs2p59+erDGqlKKBQsWiMALQhSiefINWusnlFIXaK13O+rW9/U3oTjwtnRAN3tt6cykeLLT6tWrKSkpYePGwFDZF198kdtvvz1l/QtCuhLNFc41xsj3Mrx4T2uNKKUKlFJepVRRG/uVt89Mg9ElEqpxCrEIfAKKfPznP/9h7NixXHbZZWzcuJGzzz6blStXisALQoxE8+QrCYyL9wArW8tCqZQqANBa1yqlipRSXq11bYT9vHS0Vuzrb/JB8QJAQjWOIYmTnf7yl7/w85//nC+//JLu3bszffp0pk2bRs+ePZPWpyBkGtHK/+0mUBUKaDOtwWBgmfHeT+CHIUTklVJuQlMmdBgJ1WQ+2dnZfPXVV1x99dUsWrSIvn372m2SIKQd0cr/zbYuAlcTEPNIuMKWT4iwj9vw9CM2YM54tdLReq9C+vHNN9/w7LPPctNNN6GUol+/fqxbt47zzjtPhkQKnRrLLFcr2bEcGy1c0whUG+/dQEMrbTQBUeeMRwvfWIlpxqvE4zOaV199lVtuuYWtW7dy1FFHBWerDhw40GbLBMF+Ijm9HarxqrV+2LK4VSn1ZStt1NHszbuBmrDtjUY83kWgKLhHa10fi3EhSDw+I/n3v/9NaWkp1dUBn2LgwIHBknyCIHScaOPkVyqllpkvwButAa11NQHx9gIu02tXStUY2+uNdVm0DO20C4nHpz+HDh3iscceo3///lRXV3PUUUcxd+5c1q9fz4UXXmi3eYKQMUQL15RrrWMu3K21rjDe1lrW5YftU0lg1I4gUFlZyaRJkwC47rrreOyxxzjjjDNstkoQMo9oIn8BELPICw7EQZWZTLTWwQeoY8eO5YUXXmDChAlcd911NlsmCJlLtOB2yHBHS/EQe5CHrvGTCoGPcbKT1prly5dzwQUX0NjYCECPHj2oqakRgReEJBPNky8xZqfWExhCeQHQJ2VWhTF/cIHkq2kvNlRmstLQ0MCECRN47bXXAPD5fMFCHoIgJJ8QkTfGx9cQFpNXSl2dasOsWAVeHrqmB99++y1z587lgQceYN++fbhcLioqKrjpppvsNk0QOhUtCnlrrf8aYb/WxsmnDBH49OCtt95i7NixbN68GYDRo0czd+5cvvOd79hsmSB0PsJFPtp4eA+wLbmmCJnCvn372Lx5M3379mXx4sVcdZVzMlULQmcjPMD9pFLqn2GvLcATyTTCTGsQYdou8zccSGbXQgI4fPgwq1c3F1S/8sor+eMf/8j7778vAi8ICWbVqlVmhoDsWPYPF/lxWus+Ya+zgVZTCHcUM61BpFw1H+w6DMDA+tUttgn28+GHH3L55Zdz2WWXsWbNmuD6n/3sZ/To0cNGywQhM7niiitMkd8Wy/7h4ZqzouzXau6ZVFA6ZyJM3Gi3GcnDgePaW2Pv3r3MmjWLefPmcfDgQU466ST27ImWqFQQBLsI9+RVpFJ/RurhlBMSqrn6MjtMSB3JEPgEFO2IxMsvv8yAAQMoLy/n0KFDjB8/ns2bN/OjH/0oKf0JgtB+Qjz5sMRkthMSqvn9EputSRE2j2tvi0WLFnHLLbcAMGjQIHw+H0OGDLHZKkEQopEWM4tK50y02wTBYMSIEWRnZ/Poo49SV1cnAi8IDsexIi+japzBO++8w4033sj+/fsB6N27Nx999BGlpaUccUS0CdOCIDgFx4q8jKqxl6amJsaPH89FF13EsmXLWLRoUXBbt24yKU0Q0gXHu2ISqkktWmv+8Ic/cNttt/HZZ59xxBFHMGXKFIqKkjqKVhCEJOFIkZdQjT3885//5JZbbqGmJlDc6/vf/z5LlizhvPPOs9kyQRDaiyPCNeEzXoOhGsk4mVLWrl1LTU0NWVlZPPnkk7z55psi8ILgMOKd8eoIT95ayNvqxTsqIVmaTVaKlX/961+cfvrpAIwZM4ZPPvmEm266iRNPPNFmywRBiIRZ1DvWQt6Oc5Ud68U7qAhHIvjss88YPXo0ffv2ZcuWLQAopZg2bZoIvCBkEI7w5CNROqAbjC6x24yWOHyyUlscPnyYJ554gmnTptHU1ETPnj1Zv349Z599tt2mCYKQBBwr8gC8/mbgb6anNEgR77//PsXFxbz99tsA/OAHP2DhwoXk5OTYbJkgCMnCUTGRqKNqOktKgySydOlSPB4Pb7/9NieffDLLly/nlVdeEYEXhAzHUSLv2Hh8BjB06FC6d+/OrbfeyubNmyksLEQpZbdZgiAkGUeGaxw1qiZN2bFjB0899RT33nsvSin69evHtm3bpASfIHQyHOMyywSoxHDgwAHmzp1L//79mTFjBs8++2xwmwi8IHQ+HOPJOzZUk0bj49966y1KSkp4//33ASgsLOTKK6+02SpBEOzEESK/bds2uhrvg6EapwyftAp8Csexx8OuXbuYNm0alZWVAJx11lk8/vjj/PCHP7TZMkEQEs2qVavM7ADZsezvCLc5Ozu75UqnDZ+8dS38dJ7dVkTE5/NRWVlJt27duPPOO/nwww9F4AUhQ+lojVfnIcMnI7Jv3z569uwJQGlpKZs2baKsrIxzzz3XZssEu/H7/bjdbrvNEByCIzx5IXb27dvHfffdR58+fWhsbASgZ8+ePP300yLwrVBfX09ubi5lZWVUV1dTUVFBbW1zffqmpiYqKyupr6+ntrY2GPqyUlFRQXV1NbW1tdTW1lJRUZHKU4iJ4uJimpqaqK6uDq6znntTUxO1tbXk5OREPMdEYe3T7/cnvH3r+TkB83sR7ZpG2l5fX091dXXwXMI/t0QhIp9G1NTUMHDgQO6//3527tzJihUr7DYpbfB4PLjdbkaOHElBQQFTp04lPz8/uL2wsJARI0bg8Xjwer1kZWWFiHh+fj4FBQUUFBQEtzc0NNhxKq3S2NiIx+OhoKAguM567i6XC6/Xi8vlYsSIEUmzw9pnou8qamtr8Xg8CW2zI5jC7PV6AUKcB3PZ7Xbj9Xpxu93U19cDMHv2bAoKCmhsbMTv9+NyuQAS/qMoIp8GfPrpp4waNYphw4axZcsWzj33XN544w3GjBljt2lpS3V1NVOnTgUI/tOZ/2QABQUFzJ49O7i9sbExRKw8Hg+FhYUt2q2oqAjeDdTW1gZ/SCoqKigrKwMIrjfvKKqrq8nNzQ162aY3bt5tRPMOzTsPc3t9fT1+v7+FyLRFeDumfebdiumFmnbFYls8/ZnXy+wnfDmcmpqakM/CtMPcN/z6RrI3/JiOUFdXF7THKuImeXl5FBYWBj8fj8dDZWUlgwcPxu/3U1RUFDy+oKAAn8/XYZusODMm75SRNQ5g+fLlFBUVsXv3bo488kjuvfdeJk+eTPfu3e02LfmcEmf46eONbe6ybt06Ghsbqampoby8PLgumrfZ1NTEunXryMvLa7HN9NxMqqurcbvdeDweysrKKC8vD/7DWv95vV4vxcXFId62z+fD5XKRlZWFz+ejrKyMkSNH4vF4KC4ubtF3RUUFXq8Xj8dDY2MjlZWVQbEIt8uktrY2GOJrampqtZ3i4uKg51lcXExNTQ1+v59169ZRU1PTqm2tEam/hoaG4J2S3+/H5/OFLIdj2g4Br9cUyvz8fLxeb4vrG34tIx0TqY/ly5dHPIfwKmlWewC+/PLLkGWXy0VxcTGFhYXBvsy7wKysLIqLiykvL3e2J6+UKlBKeZVSLWrEKaVcSimPsU95TA06bWSNjZx44ons3r2bH/3oR2zYsIFp06Z1DoFPEnl5eXi9XvLz84OeutvtjiomLpcLt9vNunXrWmwPP8bqYZo/INEIDzcUFhaGiLB591BfXx9RSGtqaoKi4Ha7g9W8WsMUQDNc01o7VvvM91lZWTHZFo3a2tqI/U2fPh2fz0dOTg5NTU0tllvD7XZTVFTUYj+r/eH2RjvGisvloqioKOIr0r7m5xbtvL1eLw0NDbhcrmB4JycnB5fLRW5ubsgdkXmdE0WHPXmlVAGA1rpWKVWklPJqra33QCOM7ZVKqcFKqSKtdWz3eJ1wZM1XX33FK6+8wsiRIwG48soreeedd8jLy+t8uWZi8Mzbi8vlCt5W5+Xl0djYGBR1CA3nmDH48FEr4SKRk5MT4ilbwz9teWcjRoxg3LhxTJ8+HSAY5vF4PBHFyOPxBO3x+/0MHjw45nPvaDtt2RaN+vr6iP3V1tZSVVUVfPjtdrtDlluLv5uhndZqEIfbG8sx8XjygwcPDl4Hv98f8qzHtNH8Lk2fPp3ly5czePDgqN+VRJOIcM1gYJnx3g94gKDIhwm6G2jb5eiEaK158cUXmThxIjt37uSUU07h0ksvBWj3P7DQjCno1odg5eXl1NbWkpeXx+uvvx4iKI2NjSHeeE1NDRUVFbjd7uA/ZPht/tSpUykrKyMrK4vGxka8Xi+DBw8OiZWb4Z/6+vqg6AHBUI25PHXq1JAHv+F9lZeXB7ebImK2aW3X3O73+1m2bFnwrsTv97N8+fJW2zFtNt+bXrj1mEi2mW3V19ezbNmyqMea/ZnPKtxud0hYy1wOJ/zH0+VyBX84qqurgz/g5nUIv5amqFqPCe/H9ORjoaCgIBjzb2pqCl6P/Px8ampqKCoqCv54mWEiIGSEl7WvRAu+0lp3rAGlfIBPa12vlPIC+Vrrsgj7uYEyrXWL+7sZM2bof3kDHsxS36TmcE0SPbmY+e0lgb9JLBayfft2JkyYEBwtk5eXx9KlSzn//POT1qcgpCvmD3UmzgWI59yUUjO11jPa2i8RnnwTEEsQqSCSwENoWgNT4L8cNIATEmCckzlw4ACPPvooM2fO5JtvvuG4447joYceoqSkhK5du7bdgCB0Qrxeb/AhdyZhhnwinZcllYGV7FjaTYTI1wEu433EcIxSqkBrXWG892itQ8YYZWdn86+wY054pSoBpjmb+++/nwceeACAG2+8kUceeYSTTz7ZZqsEwflECuOkO+YchkiYxbutpKyQt9a6GnAboRqX+dBVKVVj/PUC5Uqp9Uqp9cTm9Wcs1vDYpEmTGDJkCK+99hrPPfecCLwgCAknIePkTS+d0Aeu+cbfWqDT15jTWvO73/2O//mf/6Gmpobu3bvTu3dv3n777c43akYQhJThiBmvb39+yG4TksqmTZu48sor+dWvfsWbb77Jc889F9wmAi8IQjJxhMh/ti8QwnBcwZAO8t///pe7776b733ve7zxxhv07t2bp59+WtIRCIKQMhyV1sBRtV07WBHq9ddfp7i4ODh9edy4ccyZMyfhs9kEIRxJNSxYySzXOZF0sCLUzp07aWho4LzzzmPNmjVUVlaKwNuIpBpObarh2tpaevXqFbzGZWVl5ObmBmf+FhcXB9MQR0r01hZOSjXs5DTDQOCBoN2vQb++S49dvU9rrbU+uX/gZTePXRx4xcjBgwd1XV1dcPnw4cP697//vd6/f38yrBPaQUFBgV6/fn1wOfD1D+D1evWuXbuCy1VVVbq8vDxke0NDQ3B5/fr1uqioKLkGt4OCgoKo663n7vF4Qs43WbaYfe7atUu7XK7gtpqamna3W1NTE/JZ2ElVVZWuqqrSWmvt8/lanFdNTU3wGljfm5+Tz+cLnktVVVVc5wXM0DHoq3jyCaC+vp6LLrqIoUOHsmXLFiDwQPUXv/gF3bo5KAQlBJFUw9HbSVSq4ZEjR7JsWSDjybp16/B6vS3S8NbX1wevUXi/4fuaOCnVsNPTDIPDYvKrVq3iCruNiIM9e/Zwzz33sHDhQg4fPsxpp53Gp59+ytlnn223aRnBTWu+jWv/pUN7tLmPpBpOXarhgoKC4HWAgOj7fD7Ky8uDoUuPxxOSC8jar8/ni5icLNmphp2eZjgtC3mbhM/ocipaa6qrq+nfvz+PPfYYSikmT57Mpk2bGDp0qN3mCa0gqYZTm2rY7XYH87EUFBRQW1vLunXromaWjLfiUzJSDTs9zXB6F/JOk2Ih9913H7NmzQLgwgsvZMmSJQwaNMheozKQWDzz9iKphtvfTjyphk1P1frjkciiGMlINZxJaYbBaSKfJsVCfv7zn+Pz+Zg5cyZFRUV06eKoGyIhApJqOLWphq3b6urqgsvhNV+tfZkCbO03kggmO9VwJqUZhgSkGk4EF4y9W3vG3sPSERcEVtiRYjjauPhb1wZnqS5atCg4Q3Xfvn307NkzxUYKgpCpqYbjPa9YUw2LC2oSQeD/02sQY8eO5fLLL2fJkiU8//zzwW0i8IJgD5FG6aQ7raUZ7ijOCtc4gVvXorXmqaee4o5Jd9DY2Ej37t2ZPn06P/nJT+y2ThAEMi/VcGtphjuKiHwYGzZs4Oabb2b16tUAXH311SxatIi+ffvabJkgCEL8OC9cY/ND1+rqalavXs13vvMdnnnmGWpqakTgBUFIW5znyf9+Scq7/OyzzzjJeF9WVsbBgweZPHkyvXr1SrktgiAIicR5nnwK+fe//01hYSEDBw6kce8BIPBAddasWSLwgiA4klWrVpmTobJj2b9TivzBgwdZsGAB55xzDtXV1XzzzTes/9deu80ShISQyMlGgvOId8ZrpxP5uro6LrzwQkpLS/n666/52c9+xsaNG8k/x2W3aUISkVTDuUH7Kysrk5pmGJyVChjaTgfcq1cv8vPzQyaG5eTkkJubG5Km2WnnFQvOi8knkfJfXsr0369Bazi9V3cWFpzFTwd+Bn+60W7ThCTj8Xhwu93BRFUQyBRqTgYsLCykqqoqJK1BRUVFcEp6fn4+Pp8vOI65vr4+mGjKSTQ2NuLxeFrknjFn+ZrrTaGPdWZnPNTW1sadgyaZmMLs9XqDmSfDhytWVVWFrGtsbAx+vvX19bhcrpAkYuk0EctZnnySR9YMOa6Rrkpx+1Uns/HOQfx0YFgyoHYUBxHSk86eanjEiBHBtA3h9pjrTEE07TPvCPx+P9XV1VGTkzkpFTC0nQ4YAndy1jCXVfCtop6sdMDJxFmefIJH1jQ0NPDKK69w6623AnBl3+PZet8FnHbv+oT2IySJ314S3/63rm1zl86catiKmbslkj3hqXhramqCaX/N62CmAo52zUzsTgUcbg+0TAcMAc/dTP1rPa9Idzvp9szDWZ58gvj222954IEHOO+885g4cSJr1qwJbjutV/IyGwrOpzOnGrbS1NTU4s7EJFIqXjN7pOmBt5Ze14rdqYDN/duyt6ioKBiSscbdI13XdCvj6RhPfmD9ahja8Wm9q1at4uabb2bz5s0AjB49WiYzpSsxeObtpbOnGl6+fHkwfBROpFS8I0eODBYPKS4ujjnmbncqYGg7HXBlZSV5eXktzqmtNMrpgmNEvnTORJjY/uyTX3zxBXfccQdPP/00AH379mXx4sVcddVViTJRSGMk1bA/eKdg/uCYgmim9TWPi5S+t6CgINhmTk5OxPCViZNSAUPb6YBHjBgRfM5g7g/NIZzWzi8dcEyq4Xdfe6FDKYYnTJjA448/To8ePbjrrruYOnUqPXqEhWbMGG8SPURB6OxkaipgcNa5xZpq2DGefHs4cOBAsFD2jBkz+Pzzz3nwwQfp06ePzZYJQufF6/UGH0JnEslMB5xMHPXg1ShO2yZ79+6lrKyMvLw89u/fD0Dv3r1Zvny5CLwgOIBMSwUMyU0HHA/xpjVIu3DNihUrmDBhAtu3b0cpeKX4HH5wbpx5ZiRcIwhCmpN+4Zo2JkLt3LmTiRMn8sc//hGAQacehe9GN0POPDa+fmTCkyAInQjniHwrE6GefPJJbrvtNr7++muOOeYYZs2axQSWcURXJV65IAhCKzgqJh+Nbt268fXXX3P99dezadMmSktLAwIvCIIgtIojRb6pqYlXX301uDxmzBjefPNNnn/+eU477TQbLUs+sT587gzItWhGrkUzci2CZMeyk6NEXmvNs88+yznnnMPw4cPZsmULEMgWeOmll9psXWqQL3Azci2akWvRjFyLINmx7JSQmLxSqgBoAtxa6xYp89raDvDPf/6T8ePHB7PODR06FCeM/BEEQUhnOuzJGwKO1rrWWPbGsx3g03dXM3DgQGpra8nKymLp0qW88cYbMY95T8Qvu1PacIINTmnDCTY4pQ0n2OCUNpxgg1PaiIVEhGsGA2b2JT8Qnrmore18+v/e5Ntvv+VXF57IP253M3bvk3R5fGggDUG0lwWnXHD5Aie2DSfY4JQ2nGCDU9pwgg1OaSMWOjwZSinlA3xa63rDS8/XWpfFut3Y5y3g27CmtxFjDUMCsalY9830Npxgg1PacIINTmnDCTY4pQ0n2BBvG9m0jMH30Fq3OfEnETH5JqC1BMttbScWQwVBEIT4SUS4pg5wGe/dQHiW/ba2C4IgCEmiwyKvta4G3EYoxmV5wFrT2nZBEAQh+aQ0QVkihlpmCq2dq1LKReCuxw0MDn+GkWnE+rkrpco7+7VQSnkIfC9MBypjEb1oxjjXYq11fivbm4hwLVI2GSoRQy0zhRjOdQSQZ/4TK6ViL4OTZsT6uRvr0yuRd5zEeC2mG9+LLKVUxl6PGPTCC/iN7X7jxy9jae0Hva1rlcoZrx0eaplBtHquWutKy6+x27JvJtLm526IWSZfA5NWr4XxY1+nlHIb35FMviZtfS/WAVXmnY3Wuj6VxjmMVq9VKkXeFbZ8QpzbMwlX2HLEczXErTHDn2O4wpYjXQt3hguaiStsOfxa5BjrGpVSPiOsl6m4wpZDroXWugnwAVVAbmpMciyusOWQa5VKkW+ig0MtM4gmYjvXAq11cZJtsZsmWrkWSilvhv/IWWmi7e9FgyFw64GMDeMRw/cCqNVa5wBNZsiik9JEK9cqlSIvQy2bafNclVIFWusK430mh67auhaNSimv8U/s7uTXos7y3kXgnztTaetaeCwhmtl0HgcxEq1eq5SJvAy1bKata2GsL1dKrVdKrSeDv8AxfC/qjXVZtLwtzShi/B9xmQ/WMnlESVvXAqhUShUZ20dk8rWAoCbkWe9YYtVOR9R4FQRBEJKDo/LJC4IgCIlFRF4QBCGDEZEXBEHIYETkBUEQMhgRecEWlFIeY/RQuVKqwBgpEXHYrDGEMu4htZY+php9TI1nPLVSyq2UqrIsF0Tb1k67yi12tZrGo5OPAxc6QEJqvApCvBhFZPzAMnO8s1KqMcq+tUqpuCeFWfqotfSxSylVa0woaut4P1BoHOcC8oHq8G0dsMt67hpQkfYP71sQ4kE8ecERGJOcTMHzWsZAt9jPnBxl/HWZnnC8idyMPjzmcRHa9ljuINwExil7Lfua8xoKDM/cZRz3dDw2GV56hWU5/PzD+273OQudDxF5wW5MocrTWvuNfD1mutRIaYVHQnACiB+YTsBTryV6DpM8iyCO01o3KaWmAusMT9pvbAtp29jWZKyrpznrIWHbqgnkGGoCGoFPY7ApaBcBL302BPMVhZx/eN8xnrMgACLygv3UAssJiCNaa7/WurKV5FuzgWKlVAOBGbAeAml3PQQSVkVinda61sjcaIY88mlOC+CnWWitbcdDlSHYWTHaFLSLwDT06RDT+RNH+4IgIi/Yj9a6yZI732N42dHwaq0LCXiwXow8Haa3G0e39TTnp3cTyP8R3nZEouTPWQ4UE/ixitemJoz0sEqpK1o7f6Pv9p6z0AkRkRdsQTVXOBqpQotfuDEq3BAIoxQY+3qM/QabycqAaiOJm8fM7dFKHy7rNqPClHmcx2gnpO2wfjHs8dJcpCK4zQzVGLl2otpksQsCoSprXhYvkB1+/uF9t9W+IFiR3DWCIAgZjHjygiAIGYyIvCAIQgYjIi8IgpDBiMgLgiBkMCLygiAIGcz/Bwuym5/ToS8NAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "y_target = []\n",
    "y_pred = []\n",
    "for batch in val_loader:\n",
    "      \n",
    "      inputs, labels = batch\n",
    "      outputs = model(inputs)\n",
    "      loss = criterion(outputs, labels)\n",
    "      numpy_array = outputs.detach().numpy()\n",
    "      y_target.extend(labels.numpy())\n",
    "      y_pred.extend(numpy_array)\n",
    "\n",
    "\n",
    "y_target = np.array(y_target)  # Example true labels\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "pred_vals = [x.argmax() for x in y_pred]\n",
    "mask = pred_vals == y_target\n",
    "accuracy = mask.sum()/len(mask) * 100\n",
    "print(f'Model working at {accuracy:0.1f}% accuracy')\n",
    "\n",
    "\n",
    "target_labels = [\"Home Loss\", \"Home Win\", \"Draw\"]\n",
    "\n",
    "def plot_roc_curve(y_true, y_pred_prob):\n",
    "\n",
    "    # Binarize the labels\n",
    "    y_true_binarized = label_binarize(y_true, classes=[0, 1, 2])\n",
    "\n",
    "    column_sums = np.sum(y_true_binarized, axis=0)\n",
    "    # print(column_sums)\n",
    "    # print(y_true_binarized)\n",
    "    # print(y_pred_prob)\n",
    "\n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "\n",
    "    for i in range(len(target_labels)):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_true_binarized[:, i], y_pred_prob[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # Plot ROC curves\n",
    "    plt.figure()\n",
    "    # colors = ['blue', 'red', 'green', 'orange']\n",
    "    for i in range(len(target_labels)):\n",
    "        plt.plot(fpr[i], tpr[i], lw=2,\n",
    "                 label='ROC curve of {0} (area = {1:0.2f})'\n",
    "                 ''.format(target_labels[i], roc_auc[i]))\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve for 3-class Classification')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "plot_roc_curve(y_target, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the trained model for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import save\n",
    "\n",
    "save(model.state_dict(), 'AFL_prediction_model_DNN.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting upcoming games"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the winners for the round!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hawthorn to win with 0.59 probability\n",
      "Western Bulldogs to win with 0.74 probability\n",
      "Essendon to win with 0.78 probability\n",
      "Port Adelaide to win with 0.98 probability\n",
      "Geelong to win with 0.88 probability\n",
      "Brisbane Lions to win with 0.98 probability\n",
      "Melbourne to win with 0.86 probability\n",
      "Sydney to win with 0.87 probability\n"
     ]
    }
   ],
   "source": [
    "%run \"./libs/predictors.py\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
