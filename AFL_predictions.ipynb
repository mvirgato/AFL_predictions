{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AFL Match Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import json\n",
    "plt.style.use(['mvstyle', 'one_piece'])\n",
    "\n",
    "import numpy as np\n",
    "import requests\n",
    "import pandas as pd\n",
    "from os.path import isfile\n",
    "from glob import glob\n",
    "import re\n",
    "import os\n",
    "\n",
    "years = np.arange(1970, 2025)\n",
    "headers = {'User-Agent':'MV_tipping_predictions'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_team_info():\n",
    "\n",
    "    '''\n",
    "    Returns a dictionary to translate team name to ID number for use \n",
    "    in neural nets\n",
    "    '''\n",
    "    if not isfile('team_data.csv'):\n",
    "        team_data = requests.get('https://api.squiggle.com.au/?q=teams;format=csv', headers=headers)\n",
    "\n",
    "        with open('team_data.csv', 'w') as f:\n",
    "            f.write(team_data.text)\n",
    "\n",
    "    team_data = pd.read_csv('team_data.csv', index_col=None)\n",
    "    # team_dict = team_data[['name', 'id']].to_dict('index')\n",
    "    names = team_data['name'].to_numpy()\n",
    "    ids = team_data['id'].to_numpy()\n",
    "\n",
    "    team_dict = {name : id_ for id_, name in zip(ids, names)}\n",
    "\n",
    "    return team_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in years:\n",
    "\n",
    "    if isfile(f'Seasonal_Data/data_{year:d}.csv'):\n",
    "\n",
    "        # print('Data already downloaded.')\n",
    "        \n",
    "        continue\n",
    "\n",
    "    response = requests.get(f'https://api.squiggle.com.au/?q=games;year={year:d};format=csv', headers=headers)\n",
    "\n",
    "    with open(f'Seasonal_Data/data_{year:d}.csv', 'w') as f:\n",
    "        f.write(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the standings for each round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounds = np.arange(1, 29)\n",
    "\n",
    "for year in years:\n",
    "    try:\n",
    "        os.mkdir(f'Standings/{year:d}/')\n",
    "    except:\n",
    "        pass\n",
    "    for round_ in rounds:\n",
    "\n",
    "        if isfile(f'Standings/{year:d}/round_{round_:d}.csv'):\n",
    "\n",
    "            # print('Data already downloaded.')\n",
    "            \n",
    "            continue\n",
    "        \n",
    "        response = requests.get(f'https://api.squiggle.com.au/?q=standings;year={year:d};round={round_};format=csv', headers=headers)\n",
    "\n",
    "        with open(f'Standings/{year:d}/round_{round_:d}.csv', 'w') as f:\n",
    "            f.write(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some helper functions for use later\n",
    "\n",
    "def get_year(file):\n",
    "    \n",
    "    file = re.sub('^Seasonal_Data/data_', '', file)    \n",
    "    file = file.rstrip('.csv')\n",
    "\n",
    "    return int(file)\n",
    "\n",
    "def get_round(file):\n",
    "    \n",
    "    file = re.sub('^Standings/\\w+/round_', '', file)    \n",
    "    file = file.rstrip('.csv')\n",
    "\n",
    "    return int(file)\n",
    "\n",
    "def read_ranking(file):\n",
    "\n",
    "    _round = get_round(file)\n",
    "\n",
    "    _df  = pd.read_csv(file)\n",
    "\n",
    "    _df.insert(loc=0, column='round', value=_round * np.ones(len(_df), dtype= int))\n",
    "\n",
    "    return _df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read in ranking, number of wins and number of losses\n",
    "# for each team for each round\n",
    "\n",
    "def standings_data(year):\n",
    "    rank_files = glob(f'Standings/{year:d}/*')\n",
    "\n",
    "    standings_frame = pd.concat(read_ranking(file) for file in rank_files)\n",
    "\n",
    "    # Fill NaN values for rank in finals rounds with the mean of the \n",
    "    # team's rank # throughout the season\n",
    "    standings_frame['rank'] = standings_frame['rank'].fillna(\n",
    "        standings_frame.groupby('id')['rank'].transform('mean')\n",
    "        )\n",
    "\n",
    "    standings_frame = standings_frame[['round', 'id', 'rank', 'wins','losses']]\n",
    "    standings_frame = standings_frame.sort_values('round')\n",
    "    standings_frame = standings_frame.reset_index(drop=True)\n",
    "\n",
    "    return standings_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_standings(main_data, standings_data):\n",
    "\n",
    "    lookup = standings_data[['round', 'id', 'rank', 'wins', 'losses']]\n",
    "\n",
    "    # Merge with standings_data to filter matching rows\n",
    "    for prefix in ['h', 'a']:\n",
    "\n",
    "        filtered_main_data = main_data.merge(lookup, left_on=['round', f'{prefix}teamid'], right_on=['round', 'id'], how='inner')\n",
    "        filtered_main_data = filtered_main_data.rename(columns= {'rank':f'{prefix}rank', 'wins': f'{prefix}wins', 'losses': f'{prefix}losses'})\n",
    "        main_data = filtered_main_data.drop('id', axis=1)\n",
    "\n",
    "    return main_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Team info to tranlate ID and team name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function to process the raw data into the statistics we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_season_data(datafile):\n",
    "\n",
    "    # Select relevant columns\n",
    "\n",
    "    dataframe = pd.read_csv(datafile)\n",
    "\n",
    "    dataframe = dataframe[['round', 'hteamid', 'ateamid', 'hscore', \n",
    "                           'ascore', 'hgoals', 'agoals', 'hbehinds', \n",
    "                           'abehinds', 'is_final', 'winnerteamid']].copy()\n",
    "\n",
    "    # Fill NaN values in winnerteamid\n",
    "    dataframe['winnerteamid'] = dataframe['winnerteamid'].fillna(0)\n",
    "\n",
    "    # Compute hteamwin using np.where()\n",
    "    dataframe['hteamwin'] = np.where(\n",
    "        dataframe['winnerteamid'] == 0, 2, \n",
    "        np.where(dataframe['winnerteamid'] == dataframe['hteamid'], 1, 0)\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    # Compute expanding mean for each team using groupby()\n",
    "    column_team_mapping = { \n",
    "        'hscore': 'hteamid', 'hgoals': 'hteamid', 'hbehinds': 'hteamid', \n",
    "        'ascore': 'ateamid', 'agoals': 'ateamid', 'abehinds': 'ateamid' \n",
    "        }\n",
    "\n",
    "    # Compute expanding means efficiently in a single loop\n",
    "    for col, team_col in column_team_mapping.items():\n",
    "        dataframe[f'{col}_ppg'] = (\n",
    "            dataframe.groupby(team_col)[col]\n",
    "            .expanding().mean()\n",
    "            .reset_index(level=0, drop=True)\n",
    "        )\n",
    "    \n",
    "    year = get_year(datafile)\n",
    "    dataframe = merge_standings(dataframe, standings_data(year))\n",
    "\n",
    "    # Select final columns\n",
    "    final_data = dataframe[['round', \n",
    "                            'hteamid', 'ateamid',\n",
    "                            'hrank', 'arank', \n",
    "                            'hscore_ppg', 'ascore_ppg', \n",
    "                            'hgoals_ppg', 'agoals_ppg', \n",
    "                            'hbehinds_ppg', 'abehinds_ppg', \n",
    "                            'hwins', 'awins', \n",
    "                            'hlosses', 'alosses',  \n",
    "                            'is_final', 'hteamwin']].copy()\n",
    "    \n",
    "    \n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine all seasonal data into one DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "round",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hteamid",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ateamid",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hrank",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "arank",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hscore_ppg",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ascore_ppg",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hgoals_ppg",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "agoals_ppg",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hbehinds_ppg",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "abehinds_ppg",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hwins",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "awins",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hlosses",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "alosses",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "is_final",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hteamwin",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "30889851-819f-4b82-9f43-a6718a6d6dce",
       "rows": [
        [
         "0",
         "1",
         "3",
         "19",
         "5.0",
         "8.0",
         "81.0",
         "70.0",
         "11.0",
         "10.0",
         "15.0",
         "10.0",
         "1",
         "0",
         "0",
         "1",
         "0",
         "1"
        ],
        [
         "1",
         "1",
         "10",
         "11",
         "3.0",
         "10.0",
         "104.0",
         "75.0",
         "15.0",
         "10.0",
         "14.0",
         "15.0",
         "1",
         "0",
         "0",
         "1",
         "0",
         "1"
        ],
        [
         "2",
         "1",
         "15",
         "12",
         "2.0",
         "11.0",
         "134.0",
         "76.0",
         "20.0",
         "11.0",
         "14.0",
         "10.0",
         "1",
         "0",
         "0",
         "1",
         "0",
         "1"
        ],
        [
         "3",
         "1",
         "14",
         "4",
         "6.0",
         "7.0",
         "105.0",
         "101.0",
         "16.0",
         "14.0",
         "9.0",
         "17.0",
         "1",
         "0",
         "0",
         "1",
         "0",
         "1"
        ],
        [
         "4",
         "1",
         "16",
         "7",
         "4.0",
         "9.0",
         "73.0",
         "61.0",
         "10.0",
         "9.0",
         "13.0",
         "7.0",
         "1",
         "0",
         "0",
         "1",
         "0",
         "1"
        ],
        [
         "5",
         "1",
         "18",
         "5",
         "12.0",
         "1.0",
         "67.0",
         "128.0",
         "9.0",
         "18.0",
         "13.0",
         "20.0",
         "0",
         "1",
         "1",
         "0",
         "0",
         "0"
        ],
        [
         "6",
         "2",
         "4",
         "3",
         "9.0",
         "4.0",
         "75.0",
         "75.0",
         "10.0",
         "11.0",
         "15.0",
         "9.0",
         "0",
         "1",
         "1",
         "0",
         "0",
         "2"
        ],
        [
         "7",
         "2",
         "5",
         "16",
         "1.0",
         "8.0",
         "107.0",
         "60.0",
         "16.0",
         "7.0",
         "11.0",
         "18.0",
         "2",
         "1",
         "0",
         "1",
         "0",
         "1"
        ],
        [
         "8",
         "2",
         "7",
         "14",
         "12.0",
         "3.0",
         "63.0",
         "149.0",
         "10.0",
         "22.0",
         "3.0",
         "17.0",
         "0",
         "2",
         "2",
         "0",
         "0",
         "0"
        ],
        [
         "9",
         "2",
         "11",
         "18",
         "10.0",
         "7.0",
         "84.0",
         "105.0",
         "11.0",
         "15.0",
         "18.0",
         "15.0",
         "0",
         "1",
         "2",
         "1",
         "0",
         "0"
        ],
        [
         "10",
         "2",
         "12",
         "10",
         "11.0",
         "2.0",
         "76.0",
         "138.0",
         "11.0",
         "19.0",
         "10.0",
         "24.0",
         "0",
         "2",
         "2",
         "0",
         "0",
         "0"
        ],
        [
         "11",
         "2",
         "19",
         "15",
         "6.0",
         "5.0",
         "88.0",
         "80.0",
         "12.0",
         "12.0",
         "16.0",
         "8.0",
         "1",
         "1",
         "1",
         "1",
         "0",
         "1"
        ],
        [
         "12",
         "3",
         "4",
         "11",
         "7.0",
         "10.0",
         "94.0",
         "61.5",
         "13.5",
         "8.0",
         "13.0",
         "13.5",
         "1",
         "0",
         "1",
         "3",
         "0",
         "1"
        ],
        [
         "13",
         "3",
         "7",
         "10",
         "12.0",
         "1.0",
         "64.0",
         "122.5",
         "9.5",
         "17.0",
         "7.0",
         "20.5",
         "0",
         "3",
         "3",
         "0",
         "0",
         "0"
        ],
        [
         "14",
         "3",
         "12",
         "19",
         "11.0",
         "6.0",
         "81.0",
         "89.5",
         "11.5",
         "13.0",
         "12.0",
         "11.5",
         "0",
         "2",
         "3",
         "1",
         "0",
         "0"
        ],
        [
         "15",
         "3",
         "14",
         "5",
         "5.0",
         "2.0",
         "108.0",
         "129.5",
         "16.0",
         "18.5",
         "12.0",
         "18.5",
         "2",
         "3",
         "1",
         "0",
         "0",
         "0"
        ],
        [
         "16",
         "3",
         "15",
         "18",
         "4.0",
         "9.0",
         "136.5",
         "93.0",
         "21.0",
         "13.5",
         "10.5",
         "12.0",
         "2",
         "1",
         "1",
         "2",
         "0",
         "1"
        ],
        [
         "17",
         "3",
         "16",
         "3",
         "8.0",
         "3.0",
         "83.5",
         "100.5",
         "12.0",
         "14.5",
         "11.5",
         "13.5",
         "1",
         "2",
         "2",
         "0",
         "0",
         "0"
        ],
        [
         "18",
         "4",
         "3",
         "14",
         "6.0",
         "4.0",
         "92.5",
         "129.0",
         "13.0",
         "18.5",
         "14.5",
         "18.0",
         "2",
         "3",
         "1",
         "1",
         "0",
         "0"
        ],
        [
         "19",
         "4",
         "4",
         "15",
         "8.0",
         "2.0",
         "85.0",
         "83.5",
         "12.0",
         "12.0",
         "13.0",
         "11.5",
         "1",
         "3",
         "2",
         "1",
         "0",
         "0"
        ],
        [
         "20",
         "4",
         "5",
         "7",
         "1.0",
         "12.0",
         "118.0",
         "73.5",
         "16.5",
         "10.5",
         "19.0",
         "10.5",
         "4",
         "0",
         "0",
         "4",
         "0",
         "1"
        ],
        [
         "21",
         "4",
         "11",
         "16",
         "9.0",
         "10.0",
         "105.5",
         "58.0",
         "14.5",
         "7.5",
         "18.5",
         "13.0",
         "1",
         "1",
         "3",
         "3",
         "0",
         "1"
        ],
        [
         "22",
         "4",
         "18",
         "12",
         "7.0",
         "11.0",
         "83.5",
         "81.0",
         "12.0",
         "11.5",
         "11.5",
         "12.0",
         "2",
         "0",
         "2",
         "4",
         "0",
         "1"
        ],
        [
         "23",
         "4",
         "19",
         "10",
         "5.0",
         "3.0",
         "85.5",
         "103.0",
         "11.5",
         "14.333333333333334",
         "16.5",
         "17.0",
         "3",
         "3",
         "1",
         "1",
         "0",
         "1"
        ],
        [
         "24",
         "5",
         "5",
         "3",
         "3.0",
         "6.0",
         "103.0",
         "96.33333333333333",
         "14.333333333333334",
         "14.0",
         "17.0",
         "12.333333333333334",
         "4",
         "3",
         "1",
         "1",
         "0",
         "0"
        ],
        [
         "25",
         "5",
         "14",
         "11",
         "5.0",
         "9.0",
         "101.66666666666667",
         "69.0",
         "15.0",
         "9.333333333333334",
         "11.666666666666666",
         "13.0",
         "4",
         "1",
         "1",
         "4",
         "0",
         "1"
        ],
        [
         "26",
         "5",
         "7",
         "19",
         "12.0",
         "4.0",
         "67.66666666666667",
         "102.0",
         "10.0",
         "15.0",
         "7.666666666666667",
         "12.0",
         "0",
         "4",
         "5",
         "1",
         "0",
         "0"
        ],
        [
         "27",
         "5",
         "10",
         "18",
         "2.0",
         "8.0",
         "104.0",
         "87.33333333333333",
         "14.5",
         "12.666666666666666",
         "17.0",
         "11.333333333333334",
         "4",
         "2",
         "1",
         "3",
         "0",
         "1"
        ],
        [
         "28",
         "5",
         "12",
         "4",
         "11.0",
         "7.0",
         "74.66666666666667",
         "120.5",
         "10.333333333333334",
         "18.0",
         "12.666666666666666",
         "12.5",
         "0",
         "2",
         "5",
         "2",
         "0",
         "0"
        ],
        [
         "29",
         "5",
         "16",
         "15",
         "10.0",
         "1.0",
         "71.33333333333333",
         "79.0",
         "9.666666666666666",
         "11.0",
         "13.333333333333334",
         "13.0",
         "1",
         "4",
         "4",
         "1",
         "0",
         "0"
        ],
        [
         "30",
         "6",
         "3",
         "7",
         "3.0",
         "12.0",
         "110.66666666666667",
         "81.66666666666667",
         "16.0",
         "11.666666666666666",
         "14.666666666666666",
         "11.666666666666666",
         "4",
         "0",
         "1",
         "6",
         "0",
         "1"
        ],
        [
         "31",
         "6",
         "4",
         "10",
         "8.0",
         "2.0",
         "87.75",
         "102.5",
         "12.5",
         "14.5",
         "12.75",
         "15.5",
         "2",
         "5",
         "3",
         "1",
         "0",
         "0"
        ],
        [
         "32",
         "6",
         "11",
         "5",
         "9.0",
         "4.0",
         "106.66666666666667",
         "114.66666666666667",
         "15.0",
         "16.333333333333332",
         "16.666666666666668",
         "16.666666666666668",
         "2",
         "4",
         "4",
         "2",
         "0",
         "1"
        ],
        [
         "33",
         "6",
         "15",
         "14",
         "1.0",
         "6.0",
         "146.0",
         "111.33333333333333",
         "22.0",
         "15.666666666666666",
         "14.0",
         "17.333333333333332",
         "5",
         "4",
         "1",
         "2",
         "0",
         "1"
        ],
        [
         "34",
         "6",
         "16",
         "12",
         "10.0",
         "11.0",
         "80.0",
         "84.33333333333333",
         "10.75",
         "12.0",
         "15.5",
         "12.333333333333334",
         "2",
         "0",
         "4",
         "6",
         "0",
         "1"
        ],
        [
         "35",
         "6",
         "18",
         "19",
         "7.0",
         "5.0",
         "93.0",
         "99.0",
         "13.333333333333334",
         "14.5",
         "13.0",
         "12.0",
         "3",
         "4",
         "3",
         "2",
         "0",
         "1"
        ],
        [
         "36",
         "7",
         "3",
         "11",
         "2.0",
         "9.0",
         "101.75",
         "61.25",
         "14.5",
         "8.25",
         "14.75",
         "11.75",
         "5",
         "2",
         "1",
         "5",
         "0",
         "1"
        ],
        [
         "37",
         "7",
         "5",
         "15",
         "4.0",
         "3.0",
         "108.0",
         "79.75",
         "15.25",
         "10.75",
         "16.5",
         "15.25",
         "5",
         "5",
         "2",
         "2",
         "0",
         "1"
        ],
        [
         "38",
         "7",
         "7",
         "18",
         "12.0",
         "7.0",
         "77.75",
         "93.25",
         "11.25",
         "13.5",
         "10.25",
         "12.25",
         "0",
         "4",
         "7",
         "3",
         "0",
         "0"
        ],
        [
         "39",
         "7",
         "10",
         "16",
         "1.0",
         "10.0",
         "100.0",
         "63.333333333333336",
         "14.0",
         "8.0",
         "16.0",
         "15.333333333333334",
         "6",
         "2",
         "1",
         "5",
         "0",
         "1"
        ],
        [
         "40",
         "7",
         "14",
         "12",
         "5.0",
         "11.0",
         "106.5",
         "86.75",
         "15.5",
         "12.25",
         "13.5",
         "13.25",
         "5",
         "0",
         "2",
         "7",
         "0",
         "1"
        ],
        [
         "41",
         "7",
         "19",
         "4",
         "6.0",
         "8.0",
         "82.0",
         "113.66666666666667",
         "11.0",
         "17.0",
         "16.0",
         "11.666666666666666",
         "4",
         "3",
         "3",
         "3",
         "0",
         "0"
        ],
        [
         "42",
         "8",
         "4",
         "18",
         "8.0",
         "7.0",
         "81.4",
         "90.6",
         "11.4",
         "13.0",
         "13.0",
         "12.6",
         "3",
         "5",
         "4",
         "3",
         "0",
         "0"
        ],
        [
         "43",
         "8",
         "11",
         "7",
         "9.0",
         "11.0",
         "113.5",
         "86.5",
         "16.25",
         "12.25",
         "16.0",
         "13.0",
         "3",
         "0",
         "5",
         "8",
         "0",
         "1"
        ],
        [
         "44",
         "8",
         "12",
         "5",
         "12.0",
         "2.0",
         "71.25",
         "110.0",
         "9.75",
         "15.75",
         "12.75",
         "15.5",
         "0",
         "6",
         "8",
         "2",
         "0",
         "0"
        ],
        [
         "45",
         "8",
         "14",
         "10",
         "4.0",
         "3.0",
         "103.4",
         "98.8",
         "14.6",
         "14.2",
         "15.8",
         "13.6",
         "6",
         "6",
         "2",
         "2",
         "0",
         "1"
        ],
        [
         "46",
         "8",
         "15",
         "3",
         "5.0",
         "1.0",
         "127.5",
         "97.0",
         "19.0",
         "14.0",
         "13.5",
         "13.0",
         "5",
         "6",
         "3",
         "1",
         "0",
         "0"
        ],
        [
         "47",
         "8",
         "16",
         "19",
         "10.0",
         "6.0",
         "76.2",
         "103.0",
         "10.4",
         "15.2",
         "13.8",
         "11.8",
         "2",
         "5",
         "6",
         "3",
         "0",
         "0"
        ],
        [
         "48",
         "9",
         "3",
         "12",
         "1.0",
         "12.0",
         "103.2",
         "78.8",
         "14.8",
         "11.0",
         "14.4",
         "12.8",
         "7",
         "0",
         "1",
         "9",
         "0",
         "1"
        ],
        [
         "49",
         "9",
         "4",
         "7",
         "8.0",
         "11.0",
         "98.5",
         "91.0",
         "14.166666666666666",
         "13.0",
         "13.5",
         "13.0",
         "4",
         "0",
         "4",
         "9",
         "0",
         "1"
        ]
       ],
       "shape": {
        "columns": 17,
        "rows": 9476
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round</th>\n",
       "      <th>hteamid</th>\n",
       "      <th>ateamid</th>\n",
       "      <th>hrank</th>\n",
       "      <th>arank</th>\n",
       "      <th>hscore_ppg</th>\n",
       "      <th>ascore_ppg</th>\n",
       "      <th>hgoals_ppg</th>\n",
       "      <th>agoals_ppg</th>\n",
       "      <th>hbehinds_ppg</th>\n",
       "      <th>abehinds_ppg</th>\n",
       "      <th>hwins</th>\n",
       "      <th>awins</th>\n",
       "      <th>hlosses</th>\n",
       "      <th>alosses</th>\n",
       "      <th>is_final</th>\n",
       "      <th>hteamwin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>20</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>5.944444</td>\n",
       "      <td>6.055556</td>\n",
       "      <td>68.222222</td>\n",
       "      <td>61.200000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.222222</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>4.833333</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>80.200000</td>\n",
       "      <td>56.454545</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>8.272727</td>\n",
       "      <td>8.200000</td>\n",
       "      <td>6.818182</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>21</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.944444</td>\n",
       "      <td>70.181818</td>\n",
       "      <td>63.727273</td>\n",
       "      <td>10.181818</td>\n",
       "      <td>9.090909</td>\n",
       "      <td>9.090909</td>\n",
       "      <td>9.181818</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3.611111</td>\n",
       "      <td>4.833333</td>\n",
       "      <td>71.636364</td>\n",
       "      <td>65.500000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.300000</td>\n",
       "      <td>11.636364</td>\n",
       "      <td>9.700000</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>22</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>5.944444</td>\n",
       "      <td>4.833333</td>\n",
       "      <td>69.500000</td>\n",
       "      <td>64.090909</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>9.090909</td>\n",
       "      <td>8.300000</td>\n",
       "      <td>9.545455</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9476 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     round  hteamid  ateamid     hrank      arank  hscore_ppg  ascore_ppg  \\\n",
       "0        1        3       19  5.000000   8.000000   81.000000   70.000000   \n",
       "1        1       10       11  3.000000  10.000000  104.000000   75.000000   \n",
       "2        1       15       12  2.000000  11.000000  134.000000   76.000000   \n",
       "3        1       14        4  6.000000   7.000000  105.000000  101.000000   \n",
       "4        1       16        7  4.000000   9.000000   73.000000   61.000000   \n",
       "..     ...      ...      ...       ...        ...         ...         ...   \n",
       "157     20       14       15  5.944444   6.055556   68.222222   61.200000   \n",
       "158     20        7        4  4.833333   6.166667   80.200000   56.454545   \n",
       "159     21       13       14  1.000000   5.944444   70.181818   63.727273   \n",
       "160     21        2        7  3.611111   4.833333   71.636364   65.500000   \n",
       "161     22       14        7  5.944444   4.833333   69.500000   64.090909   \n",
       "\n",
       "     hgoals_ppg  agoals_ppg  hbehinds_ppg  abehinds_ppg  hwins  awins  \\\n",
       "0     11.000000   10.000000     15.000000     10.000000      1      0   \n",
       "1     15.000000   10.000000     14.000000     15.000000      1      0   \n",
       "2     20.000000   11.000000     14.000000     10.000000      1      0   \n",
       "3     16.000000   14.000000      9.000000     17.000000      1      0   \n",
       "4     10.000000    9.000000     13.000000      7.000000      1      0   \n",
       "..          ...         ...           ...           ...    ...    ...   \n",
       "157   10.000000    9.000000      8.222222      7.200000     13     11   \n",
       "158   12.000000    8.272727      8.200000      6.818182     13     10   \n",
       "159   10.181818    9.090909      9.090909      9.181818     15     14   \n",
       "160   10.000000    9.300000     11.636364      9.700000     15     14   \n",
       "161   10.200000    9.090909      8.300000      9.545455     15     14   \n",
       "\n",
       "     hlosses  alosses  is_final  hteamwin  \n",
       "0          0        1         0         1  \n",
       "1          0        1         0         1  \n",
       "2          0        1         0         1  \n",
       "3          0        1         0         1  \n",
       "4          0        1         0         1  \n",
       "..       ...      ...       ...       ...  \n",
       "157        5        8         4         1  \n",
       "158        6        8         4         1  \n",
       "159        4        5         5         0  \n",
       "160        4        6         5         0  \n",
       "161        5        7         6         1  \n",
       "\n",
       "[9476 rows x 17 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_files = glob('Seasonal_Data/data_*.csv')\n",
    "full_data = pd.concat(process_season_data(file) for file in data_files)\n",
    "full_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Nets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process data for use in neural nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PandasDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataframe):\n",
    "        self.data = dataframe.drop(columns=['hteamwin']).values  # Features\n",
    "        self.labels = dataframe['hteamwin'].values.astype(np.int16)  # Targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.tensor(self.data[idx], dtype=torch.float32)\n",
    "        y = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'full_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [36]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m main_data \u001b[38;5;241m=\u001b[39m PandasDataset(\u001b[43mfull_data\u001b[49m)\n\u001b[1;32m      4\u001b[0m train_proportion \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.7\u001b[39m\n\u001b[1;32m      5\u001b[0m val_proportion \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m train_proportion\n",
      "\u001b[0;31mNameError\u001b[0m: name 'full_data' is not defined"
     ]
    }
   ],
   "source": [
    "main_data = PandasDataset(full_data)\n",
    "\n",
    "\n",
    "train_proportion = 0.7\n",
    "val_proportion = 1.0 - train_proportion\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "train_data, val_data = train_test_split(main_data, train_size=train_proportion, shuffle=True, random_state=42)\n",
    "\n",
    "train_loader = DataLoader(train_data, \n",
    "                          shuffle=True, \n",
    "                          num_workers=2, \n",
    "                          batch_size=batch_size\n",
    "                          )\n",
    "\n",
    "val_loader = DataLoader(val_data, \n",
    "                        shuffle=True, \n",
    "                        num_workers=2, \n",
    "                        batch_size=batch_size\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test speed of data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005278680324554443 [s/iteration]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "tstart=time.time()\n",
    "num_iter=100\n",
    "ctr=num_iter\n",
    "for batch in train_loader:\n",
    "    ctr -=100\n",
    "    if ctr <= 0: break\n",
    "print((time.time()-tstart)/num_iter,'[s/iteration]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense Neural Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the neural network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_nodes = 24\n",
    "output_nodes = 3\n",
    "\n",
    "class DenseNN(nn.Module):\n",
    "    def __init__(self,inputNum):\n",
    "\n",
    "        super(DenseNN, self).__init__()\n",
    "        \n",
    "        self.inputNum=inputNum\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=inputNum, out_features=hidden_nodes)  # Input layer\n",
    "        self.fc2 = nn.Linear(in_features=hidden_nodes, out_features=hidden_nodes)     # Hidden layer\n",
    "        self.fc3 = nn.Linear(in_features=hidden_nodes, out_features=hidden_nodes)     # Hidden layer\n",
    "        self.fc4 = nn.Linear(in_features=hidden_nodes, out_features=hidden_nodes)     # Hidden layer\n",
    "        # self.fc5 = nn.Linear(in_features=hidden_nodes, out_features=hidden_nodes)     # Hidden layer\n",
    "        self.fc5 = nn.Linear(in_features=hidden_nodes, out_features=output_nodes)     # Output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = x.view(-1, self.inputNum)   # Flatten the input\n",
    "        \n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = torch.relu(self.fc4(x))\n",
    "        # x = torch.relu(self.fc5(x))\n",
    "        x = self.fc5(x)\n",
    "\n",
    "        return F.softmax(x, dim=1)\n",
    "        # return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch:  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch:  9  loss =  1.064986679289076\n",
      "batch:  19  loss =  1.0195106738492061\n",
      "batch:  29  loss =  0.9852241257141376\n",
      "batch:  39  loss =  0.9605697225301694\n",
      "batch:  49  loss =  0.9400070127175779\n",
      "batch:  59  loss =  0.9198181194774175\n",
      "End train epoch, mean loss:  0.9077584805773266\n",
      "batch:  9  loss =  0.7801739176114401\n",
      "batch:  19  loss =  0.7904747599049619\n",
      "batch:  29  loss =  0.7871832662615282\n",
      "End val epoch, mean loss:  0.7871832662615282\n",
      "In epoch:  1\n",
      "batch:  9  loss =  0.7970087395773994\n",
      "batch:  19  loss =  0.7835759457788969\n",
      "batch:  29  loss =  0.7836184707181207\n",
      "batch:  39  loss =  0.7837470586483295\n",
      "batch:  49  loss =  0.783021825916913\n",
      "batch:  59  loss =  0.7792665897789648\n",
      "End train epoch, mean loss:  0.7788864302991042\n",
      "batch:  9  loss =  0.7596496012475755\n",
      "batch:  19  loss =  0.7608277640844646\n",
      "batch:  29  loss =  0.7671832771136843\n",
      "End val epoch, mean loss:  0.7671832771136843\n",
      "In epoch:  2\n",
      "batch:  9  loss =  0.7616101106007894\n",
      "batch:  19  loss =  0.7641948304678264\n",
      "batch:  29  loss =  0.772975128272484\n",
      "batch:  39  loss =  0.7730514361308172\n",
      "batch:  49  loss =  0.7763452323115602\n",
      "batch:  59  loss =  0.7719539555452638\n",
      "End train epoch, mean loss:  0.7681220467410871\n",
      "batch:  9  loss =  0.745660490459866\n",
      "batch:  19  loss =  0.7656042356240121\n",
      "batch:  29  loss =  0.7646383314297117\n",
      "End val epoch, mean loss:  0.7646383314297117\n",
      "In epoch:  3\n",
      "batch:  9  loss =  0.7780035866631402\n",
      "batch:  19  loss =  0.7841690841474032\n",
      "batch:  29  loss =  0.7752343395660664\n",
      "batch:  39  loss =  0.7725546375299112\n",
      "batch:  49  loss =  0.7711185752129068\n",
      "batch:  59  loss =  0.7689498299259251\n",
      "End train epoch, mean loss:  0.766235545500001\n",
      "batch:  9  loss =  0.7640979819827609\n",
      "batch:  19  loss =  0.7552545509840313\n",
      "batch:  29  loss =  0.7608502281123194\n",
      "End val epoch, mean loss:  0.7608502281123194\n",
      "In epoch:  4\n",
      "batch:  9  loss =  0.7638358341323005\n",
      "batch:  19  loss =  0.7659946931035895\n",
      "batch:  29  loss =  0.7662491428441015\n",
      "batch:  39  loss =  0.7652336527139713\n",
      "batch:  49  loss =  0.7657896791185651\n",
      "batch:  59  loss =  0.7622399138191999\n",
      "End train epoch, mean loss:  0.7620878210708276\n",
      "batch:  9  loss =  0.7589710884624057\n",
      "batch:  19  loss =  0.7612580531521848\n",
      "batch:  29  loss =  0.7604303606625261\n",
      "End val epoch, mean loss:  0.7604303606625261\n",
      "In epoch:  5\n",
      "batch:  9  loss =  0.774596459335751\n",
      "batch:  19  loss =  0.7634230412934956\n",
      "batch:  29  loss =  0.7655380265466099\n",
      "batch:  39  loss =  0.7607224461359855\n",
      "batch:  49  loss =  0.7607047180740201\n",
      "batch:  59  loss =  0.7633301231820705\n",
      "End train epoch, mean loss:  0.7612974109934337\n",
      "batch:  9  loss =  0.755909350183275\n",
      "batch:  19  loss =  0.7611845794476961\n",
      "batch:  29  loss =  0.7627615188730175\n",
      "End val epoch, mean loss:  0.7627615188730175\n",
      "In epoch:  6\n",
      "batch:  9  loss =  0.7670895059903463\n",
      "batch:  19  loss =  0.7527377574067367\n",
      "batch:  29  loss =  0.7630574292150037\n",
      "batch:  39  loss =  0.7611465408251836\n",
      "batch:  49  loss =  0.7613415280166937\n",
      "batch:  59  loss =  0.7606136940293393\n",
      "End train epoch, mean loss:  0.7584796992700491\n",
      "batch:  9  loss =  0.7329736550649008\n",
      "batch:  19  loss =  0.7566096625829998\n",
      "batch:  29  loss =  0.7599784505778345\n",
      "End val epoch, mean loss:  0.7599784505778345\n",
      "In epoch:  7\n",
      "batch:  9  loss =  0.768694625960456\n",
      "batch:  19  loss =  0.7589128237021597\n",
      "batch:  29  loss =  0.7565446167156614\n",
      "batch:  39  loss =  0.7560767531394958\n",
      "batch:  49  loss =  0.7590182970981209\n",
      "batch:  59  loss =  0.7594836485587945\n",
      "End train epoch, mean loss:  0.7610498675659522\n",
      "batch:  9  loss =  0.7712209886974759\n",
      "batch:  19  loss =  0.7590273148135135\n",
      "batch:  29  loss =  0.7633976422507187\n",
      "End val epoch, mean loss:  0.7633976422507187\n",
      "In epoch:  8\n",
      "batch:  9  loss =  0.7502985066837735\n",
      "batch:  19  loss =  0.757291881661666\n",
      "batch:  29  loss =  0.7576574025482967\n",
      "batch:  39  loss =  0.7585669817068638\n",
      "batch:  49  loss =  0.7570237614670579\n",
      "batch:  59  loss =  0.757678859314676\n",
      "End train epoch, mean loss:  0.759452076990213\n",
      "batch:  9  loss =  0.7352184918191698\n",
      "batch:  19  loss =  0.7534790572367216\n",
      "batch:  29  loss =  0.7589100537628963\n",
      "End val epoch, mean loss:  0.7589100537628963\n",
      "In epoch:  9\n",
      "batch:  9  loss =  0.7598917682965597\n",
      "batch:  19  loss =  0.7627144518651461\n",
      "batch:  29  loss =  0.7628504757223458\n",
      "batch:  39  loss =  0.7585283059340256\n",
      "batch:  49  loss =  0.7582677262169975\n",
      "batch:  59  loss =  0.7583992026619992\n",
      "End train epoch, mean loss:  0.7595928124527433\n",
      "batch:  9  loss =  0.7586127983199226\n",
      "batch:  19  loss =  0.76409218499535\n",
      "batch:  29  loss =  0.7588920922114931\n",
      "End val epoch, mean loss:  0.7588920922114931\n",
      "In epoch:  10\n",
      "batch:  9  loss =  0.7543881800439622\n",
      "batch:  19  loss =  0.75386811557569\n",
      "batch:  29  loss =  0.7540415011603256\n",
      "batch:  39  loss =  0.7572652376615084\n",
      "batch:  49  loss =  0.7571579351717111\n",
      "batch:  59  loss =  0.7570150939084715\n",
      "End train epoch, mean loss:  0.7576291667881296\n",
      "batch:  9  loss =  0.7616793447070651\n",
      "batch:  19  loss =  0.7557478641208849\n",
      "batch:  29  loss =  0.7619112277853077\n",
      "End val epoch, mean loss:  0.7619112277853077\n",
      "In epoch:  11\n",
      "batch:  9  loss =  0.7862670355372958\n",
      "batch:  19  loss =  0.7628666915391621\n",
      "batch:  29  loss =  0.7605082269372612\n",
      "batch:  39  loss =  0.7612893321575263\n",
      "batch:  49  loss =  0.7588408796154723\n",
      "batch:  59  loss =  0.7596311639931242\n",
      "End train epoch, mean loss:  0.7565566434789059\n",
      "batch:  9  loss =  0.7694079147444831\n",
      "batch:  19  loss =  0.755348707500257\n",
      "batch:  29  loss =  0.7613586988942377\n",
      "End val epoch, mean loss:  0.7613586988942377\n",
      "In epoch:  12\n",
      "batch:  9  loss =  0.7549645569589403\n",
      "batch:  19  loss =  0.7600006743481285\n",
      "batch:  29  loss =  0.7618946556387276\n",
      "batch:  39  loss =  0.7597959958589994\n",
      "batch:  49  loss =  0.7590240714501362\n",
      "batch:  59  loss =  0.7587118805465052\n",
      "End train epoch, mean loss:  0.7587783167611307\n",
      "batch:  9  loss =  0.7788060042593214\n",
      "batch:  19  loss =  0.7598882568509955\n",
      "batch:  29  loss =  0.7646552406508347\n",
      "End val epoch, mean loss:  0.7646552406508347\n",
      "In epoch:  13\n",
      "batch:  9  loss =  0.7481396396954855\n",
      "batch:  19  loss =  0.7577990575840599\n",
      "batch:  29  loss =  0.7518575808097576\n",
      "batch:  39  loss =  0.7557041308818719\n",
      "batch:  49  loss =  0.7543881085454202\n",
      "batch:  59  loss =  0.7538572529614982\n",
      "End train epoch, mean loss:  0.7551905939828104\n",
      "batch:  9  loss =  0.7496220138337877\n",
      "batch:  19  loss =  0.7677833688886542\n",
      "batch:  29  loss =  0.7603858462695418\n",
      "End val epoch, mean loss:  0.7603858462695418\n",
      "In epoch:  14\n",
      "batch:  9  loss =  0.758334199587504\n",
      "batch:  19  loss =  0.7589045135598433\n",
      "batch:  29  loss =  0.7574963507981136\n",
      "batch:  39  loss =  0.7584044153873737\n",
      "batch:  49  loss =  0.7550833930774611\n",
      "batch:  59  loss =  0.7545140415935193\n",
      "End train epoch, mean loss:  0.7551142057376121\n",
      "batch:  9  loss =  0.7642117473814223\n",
      "batch:  19  loss =  0.7567850602300543\n",
      "batch:  29  loss =  0.7582301682439344\n",
      "End val epoch, mean loss:  0.7582301682439344\n",
      "In epoch:  15\n",
      "batch:  9  loss =  0.7637037767304314\n",
      "batch:  19  loss =  0.7492424626099435\n",
      "batch:  29  loss =  0.7456852547053633\n",
      "batch:  39  loss =  0.7508291327036344\n",
      "batch:  49  loss =  0.7544949699421318\n",
      "batch:  59  loss =  0.7524406546253269\n",
      "End train epoch, mean loss:  0.7571795182441597\n",
      "batch:  9  loss =  0.7583066622416178\n",
      "batch:  19  loss =  0.7637164153550801\n",
      "batch:  29  loss =  0.7628878293366268\n",
      "End val epoch, mean loss:  0.7628878293366268\n",
      "In epoch:  16\n",
      "batch:  9  loss =  0.7736084196302626\n",
      "batch:  19  loss =  0.7631816142483762\n",
      "batch:  29  loss =  0.7609668147975001\n",
      "batch:  39  loss =  0.7615357377590277\n",
      "batch:  49  loss =  0.7561180725389597\n",
      "batch:  59  loss =  0.7550176422474748\n",
      "End train epoch, mean loss:  0.752940749944146\n",
      "batch:  9  loss =  0.7562414275275336\n",
      "batch:  19  loss =  0.7573287581142626\n",
      "batch:  29  loss =  0.758221315926519\n",
      "End val epoch, mean loss:  0.758221315926519\n",
      "In epoch:  17\n",
      "batch:  9  loss =  0.7455612089898851\n",
      "batch:  19  loss =  0.749239909021478\n",
      "batch:  29  loss =  0.7436989299182234\n",
      "batch:  39  loss =  0.7453969793441968\n",
      "batch:  49  loss =  0.752344941606327\n",
      "batch:  59  loss =  0.7529135225182872\n",
      "End train epoch, mean loss:  0.7536492312132422\n",
      "batch:  9  loss =  0.7684300740559896\n",
      "batch:  19  loss =  0.7633795738220215\n",
      "batch:  29  loss =  0.7587051124408327\n",
      "End val epoch, mean loss:  0.7587051124408327\n",
      "In epoch:  18\n",
      "batch:  9  loss =  0.7512654860814413\n",
      "batch:  19  loss =  0.7508533220542105\n",
      "batch:  29  loss =  0.7494607136167329\n",
      "batch:  39  loss =  0.7505950545653318\n",
      "batch:  49  loss =  0.7538114834804924\n",
      "batch:  59  loss =  0.7539870779393083\n",
      "End train epoch, mean loss:  0.7565186779890487\n",
      "batch:  9  loss =  0.7635514802402921\n",
      "batch:  19  loss =  0.7636125652413619\n",
      "batch:  29  loss =  0.7591706802105082\n",
      "End val epoch, mean loss:  0.7591706802105082\n",
      "In epoch:  19\n",
      "batch:  9  loss =  0.761709643734826\n",
      "batch:  19  loss =  0.7618149550337541\n",
      "batch:  29  loss =  0.7577563421479587\n",
      "batch:  39  loss =  0.759750899596092\n",
      "batch:  49  loss =  0.755820136897418\n",
      "batch:  59  loss =  0.7547626182184382\n",
      "End train epoch, mean loss:  0.7541016607142207\n",
      "batch:  9  loss =  0.7650580075052049\n",
      "batch:  19  loss =  0.754157332997573\n",
      "batch:  29  loss =  0.7574477915106148\n",
      "End val epoch, mean loss:  0.7574477915106148\n",
      "In epoch:  20\n",
      "batch:  9  loss =  0.749153369002872\n",
      "batch:  19  loss =  0.7449532057109632\n",
      "batch:  29  loss =  0.7488485266422403\n",
      "batch:  39  loss =  0.7516691791705596\n",
      "batch:  49  loss =  0.7526001212548237\n",
      "batch:  59  loss =  0.7517622628454435\n",
      "End train epoch, mean loss:  0.7536868008215036\n",
      "batch:  9  loss =  0.7669869528876411\n",
      "batch:  19  loss =  0.7610365968001517\n",
      "batch:  29  loss =  0.7561669226350456\n",
      "End val epoch, mean loss:  0.7561669226350456\n",
      "In epoch:  21\n",
      "batch:  9  loss =  0.7276227474212646\n",
      "batch:  19  loss =  0.7527986859020434\n",
      "batch:  29  loss =  0.7529279240246477\n",
      "batch:  39  loss =  0.7525012829364874\n",
      "batch:  49  loss =  0.751448963369642\n",
      "batch:  59  loss =  0.7528544391615916\n",
      "End train epoch, mean loss:  0.7529160567183992\n",
      "batch:  9  loss =  0.7663858864042494\n",
      "batch:  19  loss =  0.7567466434679533\n",
      "batch:  29  loss =  0.7596566594880203\n",
      "End val epoch, mean loss:  0.7596566594880203\n",
      "In epoch:  22\n",
      "batch:  9  loss =  0.7389379607306586\n",
      "batch:  19  loss =  0.7561873511264199\n",
      "batch:  29  loss =  0.7556640053617543\n",
      "batch:  39  loss =  0.7517993954511789\n",
      "batch:  49  loss =  0.7528433921385784\n",
      "batch:  59  loss =  0.751718516066923\n",
      "End train epoch, mean loss:  0.753382906984927\n",
      "batch:  9  loss =  0.7414097189903259\n",
      "batch:  19  loss =  0.7524731598402324\n",
      "batch:  29  loss =  0.7574589930731674\n",
      "End val epoch, mean loss:  0.7574589930731674\n",
      "In epoch:  23\n",
      "batch:  9  loss =  0.7558239565955268\n",
      "batch:  19  loss =  0.7490207960731105\n",
      "batch:  29  loss =  0.749296116417852\n",
      "batch:  39  loss =  0.7534452416957953\n",
      "batch:  49  loss =  0.7538250441453895\n",
      "batch:  59  loss =  0.7563423777030687\n",
      "End train epoch, mean loss:  0.7544019373495188\n",
      "batch:  9  loss =  0.7598898278342353\n",
      "batch:  19  loss =  0.7583232208302146\n",
      "batch:  29  loss =  0.7604284923652123\n",
      "End val epoch, mean loss:  0.7604284923652123\n",
      "In epoch:  24\n",
      "batch:  9  loss =  0.7662606702910529\n",
      "batch:  19  loss =  0.7550333581472698\n",
      "batch:  29  loss =  0.7515025467708193\n",
      "batch:  39  loss =  0.7527185709048541\n",
      "batch:  49  loss =  0.754491309730374\n",
      "batch:  59  loss =  0.7530241851079262\n",
      "End train epoch, mean loss:  0.7529093534199159\n",
      "batch:  9  loss =  0.7589606112904019\n",
      "batch:  19  loss =  0.7576387775571722\n",
      "batch:  29  loss =  0.7569868770138971\n",
      "End val epoch, mean loss:  0.7569868770138971\n",
      "In epoch:  25\n",
      "batch:  9  loss =  0.7340606384807162\n",
      "batch:  19  loss =  0.7433033428694072\n",
      "batch:  29  loss =  0.7420264009771675\n",
      "batch:  39  loss =  0.746459471873748\n",
      "batch:  49  loss =  0.7539024620640035\n",
      "batch:  59  loss =  0.7554442821922949\n",
      "End train epoch, mean loss:  0.7543054436569783\n",
      "batch:  9  loss =  0.7589196099175347\n",
      "batch:  19  loss =  0.7494567287595648\n",
      "batch:  29  loss =  0.7567361531586483\n",
      "End val epoch, mean loss:  0.7567361531586483\n",
      "In epoch:  26\n",
      "batch:  9  loss =  0.7595851156446669\n",
      "batch:  19  loss =  0.7561380580851906\n",
      "batch:  29  loss =  0.7509642942198391\n",
      "batch:  39  loss =  0.7564622866801727\n",
      "batch:  49  loss =  0.7550760933331081\n",
      "batch:  59  loss =  0.7519224407309193\n",
      "End train epoch, mean loss:  0.7534668427794727\n",
      "batch:  9  loss =  0.7440811594327291\n",
      "batch:  19  loss =  0.7548322207049319\n",
      "batch:  29  loss =  0.7541950180612761\n",
      "End val epoch, mean loss:  0.7541950180612761\n",
      "In epoch:  27\n",
      "batch:  9  loss =  0.7364189227422079\n",
      "batch:  19  loss =  0.7479608560863295\n",
      "batch:  29  loss =  0.7505033180631441\n",
      "batch:  39  loss =  0.7558638117252252\n",
      "batch:  49  loss =  0.755449830269327\n",
      "batch:  59  loss =  0.751673222598383\n",
      "End train epoch, mean loss:  0.751877709111171\n",
      "batch:  9  loss =  0.7415622936354743\n",
      "batch:  19  loss =  0.7496099032853779\n",
      "batch:  29  loss =  0.756729898781612\n",
      "End val epoch, mean loss:  0.756729898781612\n",
      "In epoch:  28\n",
      "batch:  9  loss =  0.7594610187742445\n",
      "batch:  19  loss =  0.7490798799615157\n",
      "batch:  29  loss =  0.7505321235492312\n",
      "batch:  39  loss =  0.7454464542560089\n",
      "batch:  49  loss =  0.748016935222003\n",
      "batch:  59  loss =  0.7509746511103743\n",
      "End train epoch, mean loss:  0.7520691449962446\n",
      "batch:  9  loss =  0.748129215505388\n",
      "batch:  19  loss =  0.7479967537679171\n",
      "batch:  29  loss =  0.7566083608002498\n",
      "End val epoch, mean loss:  0.7566083608002498\n",
      "In epoch:  29\n",
      "batch:  9  loss =  0.7488632003466288\n",
      "batch:  19  loss =  0.7447266076740465\n",
      "batch:  29  loss =  0.7451678884440455\n",
      "batch:  39  loss =  0.7470951829201136\n",
      "batch:  49  loss =  0.7498092554053482\n",
      "batch:  59  loss =  0.7515820931580107\n",
      "End train epoch, mean loss:  0.7525541052889468\n",
      "batch:  9  loss =  0.7643694480260214\n",
      "batch:  19  loss =  0.765786277620416\n",
      "batch:  29  loss =  0.7584629737097641\n",
      "End val epoch, mean loss:  0.7584629737097641\n",
      "In epoch:  30\n",
      "batch:  9  loss =  0.7631091806623671\n",
      "batch:  19  loss =  0.7644393820511667\n",
      "batch:  29  loss =  0.757205200606379\n",
      "batch:  39  loss =  0.7542649018458831\n",
      "batch:  49  loss =  0.7537147816346617\n",
      "batch:  59  loss =  0.7531266444820469\n",
      "End train epoch, mean loss:  0.7508736626425786\n",
      "batch:  9  loss =  0.772214823298984\n",
      "batch:  19  loss =  0.7671295969109786\n",
      "batch:  29  loss =  0.7670584567661943\n",
      "End val epoch, mean loss:  0.7670584567661943\n",
      "In epoch:  31\n",
      "batch:  9  loss =  0.7494608892334832\n",
      "batch:  19  loss =  0.7538002415707237\n",
      "batch:  29  loss =  0.7468462236996355\n",
      "batch:  39  loss =  0.7481610530462021\n",
      "batch:  49  loss =  0.7502617653535337\n",
      "batch:  59  loss =  0.7523398712529974\n",
      "End train epoch, mean loss:  0.7528633181728533\n",
      "batch:  9  loss =  0.7419504125912985\n",
      "batch:  19  loss =  0.753618808169114\n",
      "batch:  29  loss =  0.753438047293959\n",
      "End val epoch, mean loss:  0.753438047293959\n",
      "In epoch:  32\n",
      "batch:  9  loss =  0.7612144947052002\n",
      "batch:  19  loss =  0.7467802857097826\n",
      "batch:  29  loss =  0.7559195037545829\n",
      "batch:  39  loss =  0.7543327334599618\n",
      "batch:  49  loss =  0.7530839820297397\n",
      "batch:  59  loss =  0.7513199701147565\n",
      "End train epoch, mean loss:  0.7519878086759083\n",
      "batch:  9  loss =  0.7551045152876112\n",
      "batch:  19  loss =  0.760462202523884\n",
      "batch:  29  loss =  0.75835232282507\n",
      "End val epoch, mean loss:  0.75835232282507\n",
      "In epoch:  33\n",
      "batch:  9  loss =  0.7466126746601529\n",
      "batch:  19  loss =  0.7541981684534174\n",
      "batch:  29  loss =  0.7529891297735017\n",
      "batch:  39  loss =  0.7524563196377877\n",
      "batch:  49  loss =  0.751594852428047\n",
      "batch:  59  loss =  0.7519211587259325\n",
      "End train epoch, mean loss:  0.7526771586332748\n",
      "batch:  9  loss =  0.7552487982643975\n",
      "batch:  19  loss =  0.756554148699108\n",
      "batch:  29  loss =  0.7602870710964861\n",
      "End val epoch, mean loss:  0.7602870710964861\n",
      "In epoch:  34\n",
      "batch:  9  loss =  0.7562744683689542\n",
      "batch:  19  loss =  0.7518746946987352\n",
      "batch:  29  loss =  0.7520367379846244\n",
      "batch:  39  loss =  0.7519840414707477\n",
      "batch:  49  loss =  0.7533648585786625\n",
      "batch:  59  loss =  0.7522598939426874\n",
      "End train epoch, mean loss:  0.7508291895709821\n",
      "batch:  9  loss =  0.7525163292884827\n",
      "batch:  19  loss =  0.7577189081593564\n",
      "batch:  29  loss =  0.7592587286028368\n",
      "End val epoch, mean loss:  0.7592587286028368\n",
      "In epoch:  35\n",
      "batch:  9  loss =  0.7484689619806077\n",
      "batch:  19  loss =  0.7597867846488953\n",
      "batch:  29  loss =  0.7621918402869126\n",
      "batch:  39  loss =  0.7551332819156158\n",
      "batch:  49  loss =  0.7526839095719007\n",
      "batch:  59  loss =  0.7527815750089742\n",
      "End train epoch, mean loss:  0.75278073193422\n",
      "batch:  9  loss =  0.7479702499177721\n",
      "batch:  19  loss =  0.7506737144369828\n",
      "batch:  29  loss =  0.7527733691807451\n",
      "End val epoch, mean loss:  0.7527733691807451\n",
      "In epoch:  36\n",
      "batch:  9  loss =  0.7556412087546455\n",
      "batch:  19  loss =  0.7467362033693414\n",
      "batch:  29  loss =  0.7497864262811069\n",
      "batch:  39  loss =  0.7496683673980908\n",
      "batch:  49  loss =  0.7481234183116835\n",
      "batch:  59  loss =  0.7482255677045402\n",
      "End train epoch, mean loss:  0.7517211383848048\n",
      "batch:  9  loss =  0.7554777926868863\n",
      "batch:  19  loss =  0.753531183067121\n",
      "batch:  29  loss =  0.7595895446580032\n",
      "End val epoch, mean loss:  0.7595895446580032\n",
      "In epoch:  37\n",
      "batch:  9  loss =  0.7550853888193766\n",
      "batch:  19  loss =  0.7509640706212897\n",
      "batch:  29  loss =  0.7510606276577917\n",
      "batch:  39  loss =  0.7518257651573572\n",
      "batch:  49  loss =  0.7558054522592195\n",
      "batch:  59  loss =  0.7542459489935536\n",
      "End train epoch, mean loss:  0.7531495903854939\n",
      "batch:  9  loss =  0.759259045124054\n",
      "batch:  19  loss =  0.7535102492884586\n",
      "batch:  29  loss =  0.7550758822210903\n",
      "End val epoch, mean loss:  0.7550758822210903\n",
      "In epoch:  38\n",
      "batch:  9  loss =  0.7474862204657661\n",
      "batch:  19  loss =  0.746944857271094\n",
      "batch:  29  loss =  0.7587116237344413\n",
      "batch:  39  loss =  0.7540420110409076\n",
      "batch:  49  loss =  0.7538588643074036\n",
      "batch:  59  loss =  0.7535525742223708\n",
      "End train epoch, mean loss:  0.751879118271728\n",
      "batch:  9  loss =  0.7450820538732741\n",
      "batch:  19  loss =  0.7513816074321145\n",
      "batch:  29  loss =  0.7527127923636601\n",
      "End val epoch, mean loss:  0.7527127923636601\n",
      "In epoch:  39\n",
      "batch:  9  loss =  0.7501263618469238\n",
      "batch:  19  loss =  0.7532393179441753\n",
      "batch:  29  loss =  0.7506544692762966\n",
      "batch:  39  loss =  0.7527922101509876\n",
      "batch:  49  loss =  0.7507361538556158\n",
      "batch:  59  loss =  0.7501297522399385\n",
      "End train epoch, mean loss:  0.7505273036102751\n",
      "batch:  9  loss =  0.7562021281984117\n",
      "batch:  19  loss =  0.7583835030856886\n",
      "batch:  29  loss =  0.7524752061942528\n",
      "End val epoch, mean loss:  0.7524752061942528\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "input_num = main_data[0][0].__len__()\n",
    "model = DenseNN(input_num)\n",
    "\n",
    "\n",
    "# # Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 40\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "  print(\"In epoch: \", epoch)\n",
    "  \n",
    "  running_loss_train = []\n",
    "  running_loss_val = []\n",
    "  \n",
    "  index = 0\n",
    "  \n",
    "  for batch in train_loader:\n",
    "      \n",
    "      index = index + 1\n",
    "      inputs, labels = batch\n",
    "      # labels = labels.view(-1, 1) \n",
    "      optimizer.zero_grad()\n",
    "      # print(labels)\n",
    "\n",
    "      # Forward propagation\n",
    "      outputs = model(inputs)\n",
    "      loss = criterion(outputs, labels)\n",
    "      \n",
    "      # Backward propagation and optimize\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      running_loss_train.append(loss.item())\n",
    "\n",
    "      if index % 10 == 9:    # Print every 100 mini-batches\n",
    "        print(\"batch: \", index, \" loss = \" , np.mean(np.asarray(running_loss_train)))\n",
    "\n",
    "  print(\"End train epoch, mean loss: \", np.mean(np.asarray(running_loss_train)))\n",
    "  index = 0\n",
    "  for batch in val_loader:\n",
    "      index = index+1\n",
    "      inputs, labels = batch\n",
    "      # labels = labels.view(-1, 1) \n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      outputs = model(inputs)\n",
    "      loss = criterion(outputs, labels)\n",
    "\n",
    "      running_loss_val.append(loss.item())\n",
    "      if index % 10 == 9:    # Print every 100 mini-batches\n",
    "        print(\"batch: \", index, \" loss = \" , np.mean(np.asarray(running_loss_val)))\n",
    "\n",
    "  print(\"End val epoch, mean loss: \", np.mean(np.asarray(running_loss_val)))\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model working at 79.2% accuracy\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "y_target = []\n",
    "y_pred = []\n",
    "for batch in val_loader:\n",
    "      \n",
    "      inputs, labels = batch\n",
    "      outputs = model(inputs)\n",
    "      loss = criterion(outputs, labels)\n",
    "      numpy_array = outputs.detach().numpy()\n",
    "      y_target.extend(labels.numpy())\n",
    "      y_pred.extend(numpy_array)\n",
    "\n",
    "\n",
    "y_target = np.array(y_target)  # Example true labels\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "pred_vals = [x.argmax() for x in y_pred]\n",
    "mask = pred_vals == y_target\n",
    "accuracy = mask.sum()/len(mask) * 100\n",
    "print(f'Model working at {accuracy:0.1f}% accuracy')\n",
    "\n",
    "\n",
    "target_labels = [\"Home Loss\", \"Home Win\", \"Draw\"]\n",
    "\n",
    "def plot_roc_curve(y_true, y_pred_prob):\n",
    "\n",
    "    # Binarize the labels\n",
    "    y_true_binarized = label_binarize(y_true, classes=[0, 1, 2])\n",
    "\n",
    "    column_sums = np.sum(y_true_binarized, axis=0)\n",
    "    # print(column_sums)\n",
    "    # print(y_true_binarized)\n",
    "    # print(y_pred_prob)\n",
    "\n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "\n",
    "    for i in range(len(target_labels)):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_true_binarized[:, i], y_pred_prob[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # Plot ROC curves\n",
    "    plt.figure()\n",
    "    # colors = ['blue', 'red', 'green', 'orange']\n",
    "    for i in range(len(target_labels)):\n",
    "        plt.plot(fpr[i], tpr[i], lw=2,\n",
    "                 label='ROC curve of {0} (area = {1:0.2f})'\n",
    "                 ''.format(target_labels[i], roc_auc[i]))\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve for 3-class Classification')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "plot_roc_curve(y_target, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the trained model for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'AFL_prediction_model_DNN.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting upcoming games"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DenseNN(16)\n",
    "model.load_state_dict(torch.load('AFL_prediction_model_DNN.pth', weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Adelaide': 1,\n",
       " 'Brisbane Lions': 2,\n",
       " 'Carlton': 3,\n",
       " 'Collingwood': 4,\n",
       " 'Essendon': 5,\n",
       " 'Fremantle': 6,\n",
       " 'Geelong': 7,\n",
       " 'Gold Coast': 8,\n",
       " 'Greater Western Sydney': 9,\n",
       " 'Hawthorn': 10,\n",
       " 'Melbourne': 11,\n",
       " 'North Melbourne': 12,\n",
       " 'Port Adelaide': 13,\n",
       " 'Richmond': 14,\n",
       " 'St Kilda': 15,\n",
       " 'Sydney': 16,\n",
       " 'West Coast': 17,\n",
       " 'Western Bulldogs': 18}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team_dict = get_team_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_year = 2024\n",
    "\n",
    "season_data = pd.read_csv(f'Seasonal_Data/data_{current_year:d}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "abehinds                           12\n",
       "agoals                             13\n",
       "ascore                             90\n",
       "ateam                        Adelaide\n",
       "ateamid                             1\n",
       "complete                          100\n",
       "date              2024-08-24 19:40:00\n",
       "hbehinds                           13\n",
       "hgoals                             18\n",
       "hscore                            121\n",
       "hteam                          Sydney\n",
       "hteamid                            16\n",
       "id                              35904\n",
       "is_final                            0\n",
       "is_grand_final                      0\n",
       "localtime         2024-08-24 19:40:00\n",
       "round                              24\n",
       "roundname                    Round 24\n",
       "timestr                     Full Time\n",
       "tz                             +10:00\n",
       "unixtime                   1724492400\n",
       "updated           2024-08-24 22:20:37\n",
       "venue                          S.C.G.\n",
       "winner                         Sydney\n",
       "winnerteamid                     16.0\n",
       "year                             2024\n",
       "Name: 203, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ateamid = 1\n",
    "hteamid = 2\n",
    "season_data[season_data['ateamid']==ateamid].iloc[-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
